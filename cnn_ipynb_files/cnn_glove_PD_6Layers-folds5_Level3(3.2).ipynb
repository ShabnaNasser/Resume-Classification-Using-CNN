{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: \t\t2.0.9\n",
      "Scikit version: \t0.19.1\n",
      "TensorFlow version: \t1.4.1\n"
     ]
    }
   ],
   "source": [
    "import keras, os, pickle, re, sklearn, string, tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adadelta, adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils  import plot_model\n",
    "from sklearn import preprocessing\n",
    "from keras import optimizers\n",
    "\n",
    "print('Keras version: \\t\\t%s' % keras.__version__)\n",
    "print('Scikit version: \\t%s' % sklearn.__version__)\n",
    "print('TensorFlow version: \\t%s' % tensorflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tika import parser\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadData_nontech():\n",
    "    label_nontech=[]\n",
    "    i=0\n",
    "    for foldername in os.listdir(\"/home/shabna/Desktop/example_codes/new_sample/level3/nontech\"):\n",
    "        for file in os.listdir(\"/home/shabna/Desktop/example_codes/new_sample/level3/nontech/\"+foldername):\n",
    "    \n",
    "            try:\n",
    "                print (i, foldername, file)\n",
    "                parsedPDF = parser.from_file(\"/home/shabna/Desktop/example_codes/new_sample/level3/nontech/\"+foldername+\"/\"+file)\n",
    "\n",
    "                resume_contents=clean_doc(parsedPDF['content'])\n",
    "            #Data = resume_contents.encode('utf-8')    \n",
    "                label_nontech.append((resume_contents,foldername))\n",
    "            except UnicodeEncodeError:\n",
    "                print ('Unicode error:', file)\n",
    "            i=i+1\n",
    "    #print (label_resume)\n",
    "    return(label_nontech)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "def clean_doc(doc):\n",
    "    \"\"\"\n",
    "    Cleaning a document by several methods:\n",
    "        - Lowercase\n",
    "        - Removing whitespaces\n",
    "        - Removing stopwords\n",
    "        - Removing punctuations\n",
    "        \n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Lowercase\n",
    "    doc = doc.lower()\n",
    "   \n",
    "    tokens = doc.translate({ord(c):\"\" for c in \"\\u200b\\uf020\\u2028\\xa0\\uf0e0\\uf095\\uf041\\uf0e1\\uf0b7\\xad\"})\n",
    "    tokens = tokens.translate({ord(c):\" \" for c in \"[):,·](;•●■♦▪\"})\n",
    "    tokens = tokens.translate({ord(c):\"f\" for c in \"�\"})\n",
    "    \n",
    "    # Removing multiple whitespaces\n",
    "    tokens = re.sub(r\"\\?\", \" \\? \", tokens)\n",
    "    \n",
    "    # Split in tokens\n",
    "    tokens = tokens.split()\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # Remove punctuation\n",
    "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 marketing Bhaskar_Singh_Kolkata_15.00_yrs.doc\n",
      "1 marketing Samuel_Raja_Velapula_Bengaluru___Bangalore_5.01_yrs.docx\n",
      "2 marketing Pranshu_Gupta_Delhi_10.00_yrs.doc\n",
      "3 marketing Rachita_Vig_Pune_0.00_yrs.docx\n",
      "4 marketing Mrinal_Tiwari_Bhubaneshwar_1.00_yrs.pdf\n",
      "5 marketing Brijesh_Pradhan_Chennai_13.00_yrs.doc\n",
      "6 marketing Parvez_Ali_Hyderabad___Secunderabad_1.10_yrs.pdf\n",
      "7 marketing Ravi_Anant_Sharma_Bengaluru___Bangalore_4.09_yrs.pdf\n",
      "8 marketing shabaiz_khan_Bengaluru___Bangalore_4.08_yrs.doc\n",
      "9 marketing Bal_Mukund_Thakur_Delhi_9.00_yrs.doc\n",
      "10 marketing Sujith N V.doc\n",
      "11 marketing Chandan_Das_Hyderabad___Secunderabad_10.01_yrs.doc\n",
      "12 marketing Johny__Mumbai_10.00_yrs.docx\n",
      "13 marketing Chitrakala_Natarajan_Chennai_7.06_yrs.docx\n",
      "14 marketing Pritam_Barik_Gurgaon_3.06_yrs.pdf\n",
      "15 marketing Shaleen__Bengaluru___Bangalore_10.01_yrs.docx\n",
      "16 marketing shashi_kant_upadhyay_Chennai_3.01_yrs.docx\n",
      "17 marketing pavan_praneeth_nallamilli_Bengaluru___Bangalore_2.04_yrs.docx\n",
      "18 marketing Irfan_Shaik_Hyderabad___Secunderabad_2.02_yrs.pdf\n",
      "19 marketing Online Marketing Executive\n",
      "20 marketing B RAVIKUMAR.doc\n",
      "21 marketing peyush_rajput_Pune_8.00_yrs.doc\n",
      "22 marketing Rohit_Aggarwal_Delhi_6.00_yrs.docx\n",
      "23 marketing Pramatha_K_P__Palakkad_0.11_yrs.pdf\n",
      "24 marketing Manindra_Thelu_United_Arab_Emirates_5.00_yrs.pdf\n",
      "25 marketing Srikanth.pdf\n",
      "26 marketing Christy_Jose_Chennai_4.00_yrs.docx\n",
      "27 marketing Pratik_Sarwade_Pune_2.06_yrs.pdf\n",
      "28 marketing Naseruddin_Ahmed_Riyadh_7.03_yrs.docx\n",
      "29 marketing Chandra_Sekhar_Hyderabad___Secunderabad_7.01_yrs.docx\n",
      "30 marketing BODDU  VYOMANADH.doc\n",
      "31 marketing Praveen Kumar.doc\n",
      "32 marketing Anand Sankar_Resume.docx\n",
      "33 marketing Rakesh_N_Bengaluru___Bangalore_8.03_yrs.docx\n",
      "34 marketing Dishari_Palit_Pune_7.00_yrs.doc\n",
      "35 marketing rajdeep_singh_Delhi_10.00_yrs.docx\n",
      "36 marketing Neeti_Sharma_Noida_10.00_yrs.doc\n",
      "37 marketing Manpreet_Gambhir_Pune_3.02_yrs.pdf\n",
      "38 marketing Devshankar_Dey_Bengaluru___Bangalore_11.04_yrs.pdf\n",
      "39 marketing KAPIL_PUND_Pune_0.02_yrs.docx\n",
      "40 marketing ayush_datt_Delhi_0.00_yrs.docx\n",
      "41 marketing Braj_Bhushan_Dangi_Ahmedabad_3.05_yrs.doc\n",
      "42 marketing S.SHAHUL HAMEED.doc\n",
      "43 marketing Babulal_Gaffar_Bengaluru___Bangalore_14.00_yrs.docx\n",
      "44 marketing Hardik_Shah_Pune_8.00_yrs.pdf\n",
      "45 marketing SARAVANAN.C.doc\n",
      "46 marketing Ravi_Dixit_Delhi_9.02_yrs.docx\n",
      "47 marketing rizwan_ahmad_Delhi_3.06_yrs.docx\n",
      "48 marketing Raj_Aaryan_Bengaluru___Bangalore_14.00_yrs.docx\n",
      "49 marketing amit_malavade_Bengaluru___Bangalore_2.03_yrs.docx\n",
      "50 marketing VIVEK V.doc\n",
      "51 marketing Saiprasad_Reddy_Hyderabad___Secunderabad_5.08_yrs.doc\n",
      "52 marketing Chaitali_Rathod_Pune_4.06_yrs.docx\n",
      "53 marketing HIMANSHU_MEHTA_Gurgaon_4.02_yrs.pdf\n",
      "54 marketing NEHA_RAI_Delhi_Region_5.04_yrs.docx\n",
      "55 marketing Mounika_Panasam_Hyderabad___Secunderabad_1.10_yrs.docx\n",
      "56 marketing Priyanka___Ahmedabad_5.06_yrs.pdf\n",
      "57 marketing SHAHEER.C.doc\n",
      "58 marketing UVJ-CALPINE_MKT01.pdf\n",
      "59 marketing PRADEEP. G.doc\n",
      "60 marketing pushpa_thapiyal_Mumbai_5.05_yrs.docx\n",
      "61 marketing Jagadeesan_Periaswamy_India_19.02_yrs.pdf\n",
      "62 marketing Rashmi_Jagasia_Mumbai_10.00_yrs.doc\n",
      "63 marketing Sheel_Thakkar_Navi_Mumbai_10.04_yrs.doc\n",
      "64 marketing Anupama_Phal_Bengaluru___Bangalore_3.00_yrs.docx\n",
      "65 marketing Brijesh_Nagdeote_Pune_7.02_yrs.doc\n",
      "66 marketing prakash_shende_Pune_5.10_yrs.docx\n",
      "67 marketing jalpa_chauhan_Bengaluru___Bangalore_8.05_yrs.docx\n",
      "68 marketing Meeta_Rani_Bengaluru___Bangalore_8.00_yrs.docx\n",
      "69 marketing Gautam_Shetty_Mumbai_3.06_yrs.pdf\n",
      "70 marketing Ravi_Bhatia_Navi_Mumbai_9.05_yrs.docx\n",
      "71 marketing Prabhakar_P_Bengaluru___Bangalore_5.01_yrs.pdf\n",
      "72 marketing NARESH_KUMAR_Mumbai_5.00_yrs.doc\n",
      "73 marketing SANTHOSH.T.doc\n",
      "74 marketing Ankita_Sehgal_Mumbai_4.06_yrs.docx\n",
      "75 marketing Manju_Annie_Oommen_Bengaluru___Bangalore_8.08_yrs.doc\n",
      "76 marketing Payal_Gaur_Delhi_12.00_yrs.pdf\n",
      "77 marketing krishna_Shrivastava_Delhi_5.03_yrs.pdf\n",
      "78 marketing Anuj_Joshi_Pune_9.06_yrs.doc\n",
      "79 marketing Mukul_Paul_Chennai_11.00_yrs.docx\n",
      "80 marketing Kavita_Aroor_Bengaluru___Bangalore_16.00_yrs.pdf\n",
      "81 marketing Kshitij_Shah_Baroda_7.08_yrs.pdf\n",
      "82 marketing DeepakRChandran3.5L_4.5L_30 days.pdf\n",
      "83 marketing Chandrashekar_Manvacharya_Bengaluru___Bangalore_2.04_yrs.pdf\n",
      "84 marketing Govardhan.KG__Bengaluru___Bangalore_12.10_yrs.docx\n",
      "85 marketing Mani_Nagarajan_Chennai_13.00_yrs.doc\n",
      "86 marketing Phani.doc\n",
      "87 marketing Mamta_dubb_Delhi_1.07_yrs.pdf\n",
      "88 marketing Keshav_Asari_Pune_2.00_yrs.pdf\n",
      "89 marketing manju_kapoor_Bengaluru___Bangalore_7.00_yrs.docx\n",
      "90 marketing Manjumol_Saleesh_Bengaluru___Bangalore_7.09_yrs.docx\n",
      "91 marketing Banumathy_Subramani_Bengaluru___Bangalore_9.02_yrs.docx\n",
      "92 marketing REJEESH.K.doc\n",
      "93 marketing Nimesh A. Chitalia.doc\n",
      "94 marketing Pasi_Vaisanen_Australia_20.00_yrs.doc\n",
      "95 marketing Imran_Sidi_Singapore_3.10_yrs.pdf\n",
      "96 marketing Jai_Govind_Shukla_Noida_10.00_yrs.docx\n",
      "97 marketing Rahul_Singh_Bengaluru___Bangalore_6.06_yrs.pdf\n",
      "98 marketing Rakesh_Adduri__Hyderabad___Secunderabad_6.00_yrs.docx\n",
      "99 marketing Arindam_Chakrabarty_Bengaluru___Bangalore_7.02_yrs.doc\n",
      "100 marketing Anirudha_Sengupta_Ahmedabad_14.00_yrs.doc\n",
      "101 marketing Ramkumar.doc\n",
      "102 marketing Ankita_Singh___Pune_3.00_yrs.doc\n",
      "103 marketing BIO-DATA-VIPIN.doc\n",
      "104 marketing Nagesh_Swamy_Bengaluru___Bangalore_12.00_yrs.docx\n",
      "105 marketing puneet_verma_Ghaziabad_2.05_yrs.pdf\n",
      "106 marketing Aravind Kema.doc\n",
      "107 marketing Gopinath_B_Chennai_7.00_yrs.docx\n",
      "108 marketing RaveendraReddy.Y.doc\n",
      "109 marketing Arpit_Srivastava_Gurgaon_9.09_yrs.docx\n",
      "110 marketing Vimal Wilson Resume Experienced.docx\n",
      "111 marketing Bharti_Singh_Bengaluru___Bangalore_5.07_yrs.docx\n",
      "112 marketing Madhan__Chennai_12.00_yrs.doc\n",
      "113 marketing Laxmi_Kanth_Hyderabad___Secunderabad_9.08_yrs.docx\n",
      "114 marketing ratan_agarwal_Hyderabad___Secunderabad_4.02_yrs.doc\n",
      "115 marketing Ankush_Mehra_Dubai_7.00_yrs.doc\n",
      "116 marketing PAAWAN_GUPTA_Delhi_1.06_yrs.docx\n",
      "117 marketing Marketing Executive-JD.docx\n",
      "118 marketing MUNMUN_BISWAS_Kolkata_8.00_yrs.docx\n",
      "119 marketing Divijaa_Parthiban_Coimbatore_4.06_yrs.docx\n",
      "120 marketing Anshita_Pamnani_Mumbai_7.00_yrs.doc\n",
      "121 marketing Ganapa_Sai_Avinash_Malaysia_11.00_yrs.doc\n",
      "122 marketing Laboni_Choudhuri_Delhi_3.01_yrs.docx\n",
      "123 marketing Deepak_PG_Bengaluru___Bangalore_12.00_yrs.docx\n",
      "124 marketing Dipak_Nilakh_Mumbai_4.07_yrs.pdf\n",
      "125 marketing NAVEEN K K.doc\n",
      "126 marketing new resume mba sunish kv.docx\n",
      "127 marketing Sankar_Ganesh_Pandian_Chennai_4.06_yrs.doc\n",
      "128 marketing Pooja_Taware_Pune_1.05_yrs.docx\n",
      "129 marketing Ranjeet_Kumar_Delhi_5.01_yrs.doc\n",
      "130 marketing prince_gerald_IGnatius_Chennai_10.03_yrs.doc\n",
      "131 marketing Sai_Kiran_A.M_Hyderabad___Secunderabad_3.04_yrs.doc\n",
      "132 marketing Pooja_Sharma_Bengaluru___Bangalore_2.04_yrs.docx\n",
      "133 marketing Bhaskar_Ghosh_Hyderabad___Secunderabad_15.01_yrs.docx\n",
      "134 marketing jithin_babu_Qatar_9.06_yrs.pdf\n",
      "135 marketing AMIT_KUMAR_Navi_Mumbai_5.00_yrs.doc\n",
      "136 marketing Jitesh_Tiyyashery_Hyderabad___Secunderabad_14.00_yrs.docx\n",
      "137 marketing Rajesh_Kumar_Hyderabad___Secunderabad_10.01_yrs.docx\n",
      "138 marketing Sharmila_M_Bengaluru___Bangalore_2.08_yrs.pdf\n",
      "139 marketing raju_nagamalla_Hyderabad___Secunderabad_5.00_yrs.docx\n",
      "140 marketing RINKY_MISHRA_Delhi_2.07_yrs.pdf\n",
      "141 marketing Sreejith Sudhan Nursing Mkt.doc\n",
      "142 marketing Prerna_Katyal_Delhi_5.00_yrs.pdf\n",
      "143 marketing P.RAVI BABU.doc\n",
      "144 marketing Mustansir_Aurangabadi_Mumbai_7.05_yrs.pdf\n",
      "145 marketing shanti_Bhawnani_Noida_7.11_yrs.docx\n",
      "146 marketing ANAND I MATHAD.doc\n",
      "147 marketing Rahul_Iyer_Gurgaon_13.00_yrs.doc\n",
      "148 marketing pratap_selvan_Chennai_12.02_yrs.doc\n",
      "149 marketing Saurabh_Sawant_India_6.05_yrs.pdf\n",
      "150 hr PolankiSailatha[2_0].doc\n",
      "151 hr KasthuriVijayan[2_2].doc\n",
      "152 hr SDeepak[7_0].pdf\n",
      "153 hr PraisePTharian[2_0].pdf\n",
      "154 hr KavithaM[2_0].docx\n",
      "155 hr Nithin Ramesh.docx\n",
      "156 hr Haris[9_0].doc\n",
      "157 hr Neena_Luiz.pdf\n",
      "158 hr PRADEEPN[8_0].docx\n",
      "159 hr KripaVarijakshan[7_0].docx\n",
      "160 hr NeemaRavindran[4_5].doc\n",
      "161 hr ThamimMohammedThahir[7_0].pdf\n",
      "162 hr SARAVANAN[5_6].docx\n",
      "163 hr NEETHUCP[0_6] (1).pdf\n",
      "164 hr SOORAJS[7_0].pdf\n",
      "165 hr Pranav_P_Palghat_1.03_yrs.docx\n",
      "166 hr Meraj[3_2].docx\n",
      "167 hr SrikanthNalam[10_0].docx\n",
      "168 hr Maitreyee[9_0].doc\n",
      "169 hr DivyaNair[9_0].doc\n",
      "170 hr JubyMichael[6_0].docx\n",
      "171 hr ManasiBM[6_0].doc\n",
      "172 hr ShyneMuraleedharan[7_0].doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 hr RitaMathews[0_7].pdf\n",
      "174 hr TeoPaul[4_5].docx\n",
      "175 hr SimonDavisS[8_0].doc\n",
      "176 hr ShelinKGeorge[6_0].pdf\n",
      "177 hr GeorginaKurian[11_0].doc\n",
      "178 hr MaheshMenon[15_0].doc\n",
      "179 hr SureshKumarM[7_0].docx\n",
      "180 hr SusindharanGB[10_0].docx\n",
      "181 hr Sudhaya[11_0].pdf\n",
      "182 hr NayanaDevadas[3_9].pdf\n",
      "183 hr PARUCHURIRAMU[6_0].docx\n",
      "184 hr SharonAnbudaiyan[1_1].doc\n",
      "185 hr ShijuBhaskaran[14_0].doc\n",
      "186 hr SFelixJayabalan[11_0].doc\n",
      "187 hr PratapChandranK[9_0].doc\n",
      "188 hr Neenu_Saseendran_Cochin___Kochi___Ernakulam_2.02_yrs.docx\n",
      "189 hr PavithraB[5_5].pdf\n",
      "190 hr MeenuSunil[1_1].docx\n",
      "191 hr PragilP[3_0].docx\n",
      "192 hr Jijokuruvilla[7_0].pdf\n",
      "193 hr PradeepK[4_0].docx\n",
      "194 hr KabilanSP[7_0].doc\n",
      "195 hr SajeeshPV[6_0].doc\n",
      "196 hr JohnsonS[17_0].docx\n",
      "197 hr SwarnalathaV[4_0].docx\n",
      "198 hr Nisha_Shankar.pdf\n",
      "199 hr PrasadDS[13_0].docx\n",
      "200 hr SrinivasKuchimanchi[15_0].docx\n",
      "201 hr Swapna[10_0].doc\n",
      "202 hr JayachandranR[19_0].docx\n",
      "203 hr SHYAMKRISHNANS[3_0].docx\n",
      "204 hr MANOJP[12_0].pdf\n",
      "205 hr JERRYJPAUL[4_5].pdf\n",
      "206 hr NeerajaN[2_0].doc\n",
      "207 hr SalvinSivadas[9_0].docx\n",
      "208 hr SrinivasaReddyB[2_3].docx\n",
      "209 hr SIJUMOOTHEDATH[8_0].pdf\n",
      "210 hr jijojohn[5_10].docx\n",
      "211 hr SajeeshDominicVarghese[8_0].doc\n",
      "212 hr NIDHICHANDRAN.pdf\n",
      "213 hr ShwethaRenil[5_3].pdf\n",
      "214 hr ramachandran[4_5].doc\n",
      "215 hr MunamaSriharsha[0_0].doc\n",
      "216 hr SHAJIN_P___Thiruvananthapuram___Trivandrum_0.00_yrs.pdf\n",
      "217 hr MinuRajan[5_1].pdf\n",
      "218 hr MerritaD'cruz[5_10].doc\n",
      "219 hr Profile.docx\n",
      "220 hr KishorKumarG[19_0].doc\n",
      "221 hr Saranya_Rajendran__Kottayam_0.00_yrs.docx\n",
      "222 hr PeterEdward[11_0].docx\n",
      "223 hr HevinBabu[9_0].docx\n",
      "224 hr MilnaAbraham[2_0].docx\n",
      "225 hr SubhabharathyM[5_1].doc\n",
      "226 hr ResmiG[7_0].docx\n",
      "227 hr PRAKASHB[5_5].doc\n",
      "228 hr ReshmaRavindran[4_7].docx\n",
      "229 hr NicholasDominic[6_0].doc\n",
      "230 hr TeranceTKumar[6_0].docx\n",
      "231 hr SanthoshRavichandran[4_0].docx\n",
      "232 hr NeethuSunny[2_3].docx\n",
      "233 hr JISHNUSSALIL[3_0].docx\n",
      "234 hr IshanthKrishnanMBA[8_0].pdf\n",
      "235 hr JKesavan[25_0].doc\n",
      "236 hr ShyamSunny[3_10].pdf\n",
      "237 hr Praise__CV.pdf\n",
      "238 hr Neenu_Jijo.pdf\n",
      "239 hr SteenaBiju[5_0].docx\n",
      "240 hr SivaprasadSS[4_5].docx\n",
      "241 hr SabeelRahman[11_0].pdf\n",
      "242 hr Pranav[10_0].doc\n",
      "243 hr Ramya_nair_Cochin___Kochi___Ernakulam_2.00_yrs.docx\n",
      "244 hr PremSingh[5_6].pdf\n",
      "245 hr JohnsonJamesPalithara[20_0].docx\n",
      "246 hr PraveenPNair[5_11].doc\n",
      "247 hr Kumar[9_0].pdf\n",
      "248 hr PVVijayakumar[28_0].docx\n",
      "249 hr Prayan William- (hr admin).docx\n",
      "250 hr JanarthananA[3_5].doc\n",
      "251 hr ShrutiSharma[8_0].doc\n",
      "252 hr SwapnaJ[4_3].pdf\n",
      "253 hr KRDineshKumar[13_0].pdf\n",
      "254 hr nilutreesathomas[1_0].pdf\n",
      "255 hr PerumalPanchaksharam[11_0].docx\n",
      "256 hr NivyaPadmanabhan[2_0]-not interested.doc\n",
      "257 hr Neerajsudhakar[2_0].docx\n",
      "258 hr NKalasagarReddy[15_0].doc\n",
      "259 hr GOKULGNAIR[4_0].pdf\n",
      "260 hr SulataSahu[4_7].doc\n",
      "261 hr ReniManjesh[6_0].pdf\n",
      "262 hr Sarath_Krishna_Cochin___Kochi___Ernakulam_0.06_yrs.doc\n",
      "263 hr RasalHameed[15_0].pdf\n",
      "264 hr SureshB[8_0].doc\n",
      "265 hr SarathMurzilS[6_0].pdf\n",
      "266 hr RakeshRamakrishnan[10_0].doc\n",
      "267 hr Kannan[1_8].pdf\n",
      "268 hr SKarthik[11_0].docx\n",
      "269 hr NyjilNazeer[7_0].doc\n",
      "270 hr DIVYAMV[5_5].docx\n",
      "271 hr Prabhu[13_0].pdf\n",
      "272 hr NithyaBalakrishnan[2_6].pdf\n",
      "273 hr Ninu[3_0]-not interested.docx\n",
      "274 hr DurgaCNayak[8_0].doc\n",
      "275 hr PremkumarS[7_0].doc\n",
      "276 hr Sooraj[6_0].doc\n",
      "277 hr rekha.docx\n",
      "278 hr Nygil[6_0].docx\n",
      "279 hr sreenathb[8_0].doc\n",
      "280 hr SheebaTharol[10_0].pdf\n",
      "281 hr SarayuBabu[1_1].pdf\n",
      "282 hr Indulekha[13_0].doc\n",
      "283 hr SHANU[8_0].pdf\n",
      "284 hr Pallavi Kumari.doc\n",
      "285 hr SeebaAbdulHakim[5_0].docx\n",
      "286 hr RinyRaju[1_5]-rejected.docx\n",
      "287 hr PKishorekumar[0_10].doc\n",
      "288 hr kasiviswam[15_0].doc\n",
      "289 hr HARIKRISHNANR[6_0].doc\n",
      "290 hr Paul_Jacob.pdf\n",
      "291 hr PRIYANKASDUTH[2_8].pdf\n",
      "292 hr FasilKYousuf[1_6].docx\n",
      "293 hr HASHIMVM[4_10].pdf\n",
      "294 hr Lidia[5_2].docx\n",
      "295 hr SHINCEKURIAKOSE[6_0].docx\n",
      "296 hr Nithin_Mathew.pdf\n",
      "297 hr NishaVarghese[10_0].doc\n",
      "298 hr SRINIVASAM[10_0].docx\n",
      "299 hr GireeshPR[7_0].docx\n",
      "300 seo DEEPAKJOSE[2_4].pdf\n",
      "301 seo Harendra_kumar_Ghaziabad_4.02_yrs.doc\n",
      "302 seo Nisha_A_Thrissur___Trissur_1.06_yrs.pdf\n",
      "303 seo AnithaRaghavendra[2_3].pdf\n",
      "304 seo MonicaSharma[2_5].docx\n",
      "305 seo SukantaDas[3_3].pdf\n",
      "306 seo VenkateshP[1_3].doc\n",
      "307 seo Piyushjain[3_0].docx\n",
      "308 seo ChevvaPradeep[6_0].docx\n",
      "309 seo RajaVenkat[2_3].docx\n",
      "310 seo BaskaranG[1_1].docx\n",
      "311 seo Pradeep_Rawat_Delhi_0.08_yrs.docx\n",
      "312 seo 79906590_Gurgaon_7.02_yrs.docx\n",
      "313 seo Bhagyalaxmi[5_0].docx\n",
      "314 seo Chandu_Thomas_Coimbatore_6.02_yrs.pdf\n",
      "315 seo NithinMR[1_1].pdf\n",
      "316 seo LAXMON_GOPE_Durgapur_7.00_yrs.pdf\n",
      "317 seo sunithaparvathaneni[1_7].docx\n",
      "318 seo LOGANATHAN[3_0].pdf\n",
      "319 seo Hema_Gupta_Kolkata_6.05_yrs.pdf\n",
      "320 seo ghadiya_hardik_Surat_1.00_yrs.pdf\n",
      "321 seo KorukulaSatheesh[3_0].docx\n",
      "322 seo GargiSingh[6_0].doc\n",
      "323 seo Mahendra_Yadav_Bhopal_10.00_yrs.doc\n",
      "324 seo MrsShwetaKunteKulkarni[3_4].docx\n",
      "325 seo Asif_Khan_Bengaluru___Bangalore_6.08_yrs.docx\n",
      "326 seo SushmithaS[1_0].docx\n",
      "327 seo Gnanambigai[5_4].doc\n",
      "328 seo AtulMahajan[5_0].docx\n",
      "329 seo parshant_kumar_UNA(himachal_Pradesh)_6.00_yrs.doc\n",
      "330 seo ankurpratap[2_11].docx\n",
      "331 seo NeethuMohan[6_0].doc\n",
      "332 seo PriyankaAgarwal[5_9].docx\n",
      "333 seo Neeraj_Thakur_Chandigarh_2.00_yrs.docx\n",
      "334 seo sumit[3_6].doc\n",
      "335 seo TummalaVenkataRamya[0_8].docx\n",
      "336 seo DeepikaNair[2_0].doc\n",
      "337 seo NidhiSood[4_2].doc\n",
      "338 seo PrateekKumar[4_0].pdf\n",
      "339 seo Manasa[1_4].docx\n",
      "340 seo Haridas_G_Bengaluru___Bangalore_2.06_yrs.doc\n",
      "341 seo Albin_Thomas_Kozhikode___Calicut_0.05_yrs.pdf\n",
      "342 seo SudhanshuPandey[6_0].doc\n",
      "343 seo PranitaGhag[2_10].docx\n",
      "344 seo PARUL_KUMARI_Delhi_3.07_yrs.doc\n",
      "345 seo PAshwini[1_8].docx\n",
      "346 seo Deepak_SK__Delhi_1.00_yrs.pdf\n",
      "347 seo Raushan_Gupta__Varanasi_4.00_yrs.doc\n",
      "348 seo srinivasnaik[2_1].docx\n",
      "349 seo Heeramariapaul[2_0].docx\n",
      "350 seo Pranjali_Mahajan_Mumbai_4.00_yrs.doc\n",
      "351 seo ArthiBhagath[0_8].doc\n",
      "352 seo PrasadVelugoti[3_3].docx\n",
      "353 seo Pradeep_Kumar_Noida_5.04_yrs.doc\n",
      "354 seo jaykesh_awlu_Navi_Mumbai_2.00_yrs.docx\n",
      "355 seo juned_saiyed_Ahmedabad_7.01_yrs.doc\n",
      "356 seo Prateekagarwal[2_5].doc\n",
      "357 seo Raja_Babu_Trivedi_Delhi_8.00_yrs.docx\n",
      "358 seo UmaMaheswarReddy[4_0].doc\n",
      "359 seo RajeshKanna[1_11].docx\n",
      "360 seo Abhishek_Mall_Mumbai_5.00_yrs.docx\n",
      "361 seo DivyaN[4_0].docx\n",
      "362 seo BNaveenKumarReddy[4_7].doc\n",
      "363 seo SSanthosh[5_3].docx\n",
      "364 seo ShyamGubba[4_5].doc\n",
      "365 seo AbhishekChatterjee[2_4].doc\n",
      "366 seo JAFRUDDEN_SHAH_Gurgaon_2.02_yrs.doc\n",
      "367 seo GurpreetSingh[4_1].docx\n",
      "368 seo Dhirendra_Kumar_Delhi_2.01_yrs.docx\n",
      "369 seo Akhil[2_2].docx\n",
      "370 seo Naveen__Hyderabad___Secunderabad_11.00_yrs.docx\n",
      "371 seo Balasundaramk[2_0].doc\n",
      "372 seo PraveenKumarSingh[3_7].docx\n",
      "373 seo TMPooja[3_5].doc\n",
      "374 seo chaithanya_thakellapati_Hyderabad___Secunderabad_5.10_yrs.docx\n",
      "375 seo AshutoshRSable[1_5].docx\n",
      "376 seo Purnachandran[2_10].pdf\n",
      "377 seo Keshab_Singha_Pune_4.00_yrs.docx\n",
      "378 seo SHERINELDHOSE[1_4].docx\n",
      "379 seo Sushmita_Singh_Bengaluru___Bangalore_8.02_yrs.doc\n",
      "380 seo DeepakMishra[1_3].docx\n",
      "381 seo TamilArasi[3_5].docx\n",
      "382 seo Sindhuvwodeyar[2_0].doc\n",
      "383 seo Awadesh_Chawda_Indore_3.08_yrs.doc\n",
      "384 seo vahora_parvez_Ahmedabad_5.00_yrs.pdf\n",
      "385 seo AnandKumar[4_5].doc\n",
      "386 seo Manikandaraja[4_6].docx\n",
      "387 seo NarasimhaSainathNuvvula[4_3].doc\n",
      "388 seo DineshkumarP[1_10].docx\n",
      "389 seo sumana[1_9].docx\n",
      "390 seo Eti_Gautam_Hyderabad___Secunderabad_6.00_yrs.docx\n",
      "391 seo Naveen_Sharma_Bhiwani_1.00_yrs.docx\n",
      "392 seo KalavakoluMuniSekhar[2_8].docx\n",
      "393 seo prajith[4_1].doc\n",
      "394 seo BhargaviL[4_3].doc\n",
      "395 seo VenkatRamana[3_0].doc\n",
      "396 seo SunnyKumar[3_2].docx\n",
      "397 seo BHAVESH_CHONKAR_Mumbai_5.00_yrs.docx\n",
      "398 seo PranoyMPauly[1_9].pdf\n",
      "399 seo Pranali_Waghmare_Bengaluru___Bangalore_1.00_yrs.docx\n",
      "400 seo suresh[1_7].doc\n",
      "401 seo MSindhuja[3_0].docx\n",
      "402 seo Laxmi[2_0].doc\n",
      "403 seo CSSureshKumar[8_0].doc\n",
      "404 seo MAHADEVPRAMANIK[1_0].docx\n",
      "405 seo Paras_Nautiyal_Gurgaon_5.03_yrs.docx\n",
      "406 seo DineshMahar[2_4].doc\n",
      "407 seo sijupm[2_11].docx\n",
      "408 seo ShvetaJogi[6_0].docx\n",
      "409 seo sumith_kumar_karingula_Hyderabad___Secunderabad_1.02_yrs.docx\n",
      "410 seo ShravyaK[3_0].doc\n",
      "411 seo Venu_Gopal_Reddy_Hyderabad___Secunderabad_0.06_yrs.docx\n",
      "412 seo 14798108_Mumbai_11.00_yrs.doc\n",
      "413 seo Kanaka_Surya_Narayana_Duduku_Hyderabad___Secunderabad_0.05_yrs.pdf\n",
      "414 seo DelmyRosePJ[1_3].docx\n",
      "415 seo Manish_Yadav_Gurgaon_5.01_yrs.docx\n",
      "416 seo MOHAMEDMANSURS[3_0].docx\n",
      "417 seo SMathanbabu[2_0].doc\n",
      "418 seo VinodhiniM[2_1].doc\n",
      "419 seo PoojaSoni[4_4].doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 seo Ranjeet_kumar_Noida_3.07_yrs.doc\n",
      "421 seo Jayshree_Sasane_upadhyay_Pune_7.00_yrs.doc\n",
      "422 seo vishnu_kumar_Delhi_2.07_yrs.docx\n",
      "423 seo Divya[2_0].doc\n",
      "424 seo BhuvaneswariA[1_1].docx\n",
      "425 seo LakshmiRDevi[5_3].pdf\n",
      "426 seo SSasikiran[2_6].doc\n",
      "427 seo RajashriGHegde[1_10].doc\n",
      "428 seo AbhishekC[2_3].doc\n",
      "429 seo PShriVanadhi[1_0].doc\n",
      "430 seo Pawan_Gupta_Gurgaon_3.11_yrs.doc\n",
      "431 seo ashok__Faridabad_1.10_yrs.docx\n",
      "432 seo Anil_Pratap_Singh_Delhi_4.00_yrs.docx\n",
      "433 seo ShivaKumarG[4_11].docx\n",
      "434 seo Avik_Bhattacharya_Bengaluru___Bangalore_2.07_yrs.pdf\n",
      "435 seo SushantYM[2_7].docx\n",
      "436 seo VikasRai[5_0].doc\n",
      "437 seo PrincyJain[2_9].docx\n",
      "438 seo Suvrangsu_Das_Kolkata_0.06_yrs.docx\n",
      "439 seo KamalakarY[2_1].docx\n",
      "440 seo TintuFrancis[7_0].doc\n",
      "441 seo Tarun_Bhardwaj_Delhi_4.02_yrs.doc\n",
      "442 seo Tanmoy_Basak_Kolkata_7.00_yrs.doc\n",
      "443 seo Nikhil_Chandra_Reddy_Hyderabad___Secunderabad_3.00_yrs.doc\n",
      "444 seo LakshmiVenugopal[4_0].doc\n",
      "445 seo Balaji_D_Hyderabad___Secunderabad_8.02_yrs.docx\n",
      "446 seo Nirup_S_Ranya_Bengaluru___Bangalore_3.02_yrs.docx\n",
      "447 seo KhimsuriyaSnehaNayankumar[3_5].docx\n",
      "448 seo MohamedSalman[3_3].pdf\n",
      "449 seo Suresh_Yadav_Delhi_10.00_yrs.docx\n",
      "450 other -Mechanical Engineering Resume Sample.pdf\n",
      "451 other Autocad Experience Resume.docx\n",
      "452 other Optometrist Assistant Resume.doc\n",
      "453 other Electronics Engineer Resume.doc\n",
      "454 other machinist-resume-template.docx\n",
      "455 other Chemical Engineering Resume Sample.pdf\n",
      "456 other construction-superintendent-resume.docx\n",
      "457 other construction-resume-template.docx\n",
      "458 other Clinical-Pharmacist-Resume1.pdf\n",
      "459 other Mechanical Engineering Resume for Fresh Graduate.pdf\n",
      "460 other Designer Assistant Resume.doc\n",
      "461 other Entry Level Electrical Engineering Resume.pdf\n",
      "462 other abin austin resume.doc\n",
      "463 other Public Health Nutritionist Resume.pdf\n",
      "464 other nishant-resume-1.pdf\n",
      "465 other CURRICULAM VITAE.docx\n",
      "466 other PallaviMoreProfile.pdf\n",
      "467 other Akhil.pdf\n",
      "468 other Er. KaveryBajpaiProfile.pdf\n",
      "469 other Retail Sales Representative Resume.doc\n",
      "470 other DEEPTHIBelliyappaProfile.pdf\n",
      "471 other Autocad Electrical Engineer Resume.pdf\n",
      "472 other construction-resume-examples.docx\n",
      "473 other Mechanical Engineering Resume For Experience.doc (2)\n",
      "474 other Civil-Engineer-Resume-PDF-Free-Download.pdf\n",
      "475 other Chiropractic Doctor.pdf\n",
      "476 other PDF-Format-Automobile-Resume-Free-Template.pdf\n",
      "477 other ANAZ_A_N.pdf\n",
      "478 other resume-sample-college-student-academic.doc\n",
      "479 other Diesel Mechanic Resume.doc\n",
      "480 other CristinaIoreProfile.pdf\n",
      "481 other SathishkumarProfile.pdf\n",
      "482 other 378724878RAMESH-INSTRUMENTATION_ENGINEER.doc\n",
      "483 other Auto Mechanic Resume.doc\n",
      "484 other construction-laborer-resume.docx\n",
      "485 other Optical Lab Technician Resume.doc\n",
      "486 other sdf.docx\n",
      "487 other Civil Engineer Resume PDF.pdf\n",
      "488 other automobile-engineer-resume-template.docx\n",
      "489 other MY_CV_1.doc\n",
      "490 other Civil-Project-Engineer-Resume-PDF-Free-Download.pdf\n",
      "491 other gs.pdf\n",
      "492 other Coorporate-Lawer-Resume-Free-PDF-Downlaod.pdf\n",
      "493 other Doc-Format-Free-Automobile-Resume-Template.doc\n",
      "494 other Entry-Level-Civil-Engineer-Resume-PDF-Downlaod.pdf\n",
      "495 other Experience Electrical Engineering Resume.pdf\n",
      "496 other Mechanical Autocad Draftsman Resume.doc\n",
      "497 other Corporate Account Manager.pdf\n",
      "498 other 2d6f13feccbe4e6c27257ad0782ef29e.doc\n",
      "499 other Chemical Engineering Student Resume.pdf\n",
      "500 other Civil-Engineer-Resume-PDF-Template-Download.pdf\n",
      "501 other Sample Lab Technician Resume.pdf\n",
      "502 other resume_Ashok.doc\n",
      "503 other Jagadeeswara Resume.doc\n",
      "504 other Autocad Operator Resume.docx\n",
      "505 other Civil-Engineer-Planning-Resume-Word-Free-Download.docx\n",
      "506 other Retail-Pharmacist-Resume.doc\n",
      "507 other Mechanical Engineering Sample Resume.doc\n",
      "508 other CURRICULUM VITAEsathish.doc\n",
      "509 other Junior-Civil-Engineer-Resume-PDF-Template.pdf\n",
      "510 other Microsoft Word - YUNI_CV.pdf\n",
      "511 other cv-template-finance-financial-accountant.doc\n",
      "512 other Professional Optometrist Resume.pdf\n",
      "513 other ParulChauhanProfile.pdf\n",
      "514 other Res1-1.doc\n",
      "515 other Entry-Level-Firefighter-Resume.doc\n",
      "516 other Sales Representative Resume Cover Letter.doc\n",
      "517 other resume_4020.doc\n",
      "518 other pavankumarProfile.pdf\n",
      "519 other Optometrist Medical Assistant Resume.docx\n",
      "520 other construction-resume-samples.docx\n",
      "521 other Mechanical Engineering Resume For Fresher.doc\n",
      "522 other -English Teacher Resume Sample.pdf\n",
      "523 other Civil Engineer Resume Free Download.pdf\n",
      "524 other Psychiatrist-Resume-Template1.docx\n",
      "525 other Personal-Injury-Lawyer-Resume-PDF-Free-Template.pdf\n",
      "526 other Retail Sales Associate Resume.docx\n",
      "527 other Afeefa_Mustafa.pdf\n",
      "528 other 5932_Rajesh Electrical CV.doc\n",
      "529 other Professional Autocad Engineer Resume.pdf\n",
      "530 other Power Electronics Resume.docx\n",
      "531 other Craft Teacher Resume Sample.doc\n",
      "532 other Ehab BasuoniProfile.pdf\n",
      "533 other automobile-mechanic-resume-template.docx\n",
      "534 other Dental Lab Technician Resume.doc\n",
      "535 other Electrical Engineering Student Resume.doc\n",
      "536 other Auto Mechanic Resume Template.doc\n",
      "537 other civil-engineering-resume-examples.docx\n",
      "538 other free-manufacturing-resume-template.docx\n",
      "539 other pgdm-finance-accountant-resume-sample.doc\n",
      "540 other Pediatric Nurse Resume.pdf\n",
      "541 other construction-worker-resume.doc\n",
      "542 other Professional Lab Technician Resume Resume Templates.doc\n",
      "543 other Fresher Electrical Engineering Resume.doc\n",
      "544 other Basic.doc\n",
      "545 other Diploma Electrical Engineering Resume.doc\n",
      "546 other Free-Download-Mechanical-Engineer-Resume-Doc-Template.doc\n",
      "547 other Pharmacy-Technician-Resume2.pdf\n",
      "548 other Entry Level Optometrist Resume Templates.docx\n",
      "549 other Doctor-Assistant-Resume-Template.docx\n",
      "550 other Pawan  KumarRukmangadaProfile.pdf\n",
      "551 other Clinical Nutritionist Resume.docx\n",
      "552 other Aircraft Mechanic Resume.doc\n",
      "553 other sdfdf.doc\n",
      "554 other ff.docx\n",
      "555 other ANSAAR C.A 10_neg_immedate.pdf\n",
      "556 other NithinKailasProfile.pdf\n",
      "557 other Mechanical Engineering Resume For Fresher.doc (2)\n",
      "558 other kalamani.doc\n",
      "559 other Consultant Radiologist Resume.doc\n",
      "560 other Experienced-Civil-Engineer-Resume-PDF-Free-Download.pdf\n",
      "561 other Ram Kumar.doc\n",
      "562 other JayasankarJProfile.pdf\n",
      "563 other Electronics Technician Resume.doc\n",
      "564 other Aircraft Mechanic Resume.doc (3)\n",
      "565 other DILEEPC MProfile.pdf\n",
      "566 other automotive-body-repair-technician-resume-template.docx\n",
      "567 other Telecommunications Technician Resume.docx\n",
      "568 other Professional Doctor Curriculum Vitae.pdf\n",
      "569 other civil-engineer-resume-examples.docx\n",
      "570 other -Civil Engineering Student Resume Template.pdf\n",
      "571 other CV of Lead Engineer_Instrumentation.doc\n",
      "572 other Aircraft Mechanic Resume.doc (2)\n",
      "573 other -Entry Level Civil Engineering Resume Template.doc\n",
      "574 other Autocad Engineer Resume.doc\n",
      "575 other Automobile-Resume-Template-Free-Download-PDF.pdf\n",
      "576 other PDF-Format-Automobile-Resume-Free-Template(1).pdf\n",
      "577 other instrumentation.doc\n",
      "578 other Retail Management Sales Resume.pdf\n",
      "579 other Orthopedic-Doctor-Resume-Template.docx\n",
      "580 other Dental-Doctor-Resume-Free-PDF-Template.pdf\n",
      "581 other Experience Electronics Engineer Resume.doc\n",
      "582 other NITIN SHARMA.docx\n",
      "583 other Aviation Electronics Technician Resume.pdf\n",
      "584 other Mechanical Engineering Resume For Experience.doc\n",
      "585 other Aviation Mechanic Resume.doc\n",
      "586 other Mechanical Engineering Resume For Internship.doc\n",
      "587 other Electrical and Electronics Engineer Resume.doc\n",
      "588 other instrument-mechanic-resume-template.docx\n",
      "589 other Professional Electronics Engineer Resume.doc\n",
      "590 other KrishnaveniEIEProfile.pdf\n",
      "591 other cv-chaker-abdeljaoued.pdf\n",
      "592 other Free-Download-Civil-Engineering-Resume-Template-Doc.docx\n",
      "593 other K. Ravikumar.doc\n",
      "594 other construction-supervisor-resume.docx\n",
      "595 other Sample Radiology Résumé.pdf\n",
      "596 other ec.doc\n",
      "597 other Mechanical Engineering Student Resume.pdf\n",
      "598 other ramesh.doc\n",
      "599 other Aviation Mechanic Resume.doc (2)\n"
     ]
    }
   ],
   "source": [
    "label_nontech=LoadData_nontech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_nontech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "jdres_train_labels=[]\n",
    "jdres_train_data=[]\n",
    "\n",
    "for row in label_nontech:\n",
    "    jdres_train_data.append(row[0])\n",
    "    jdres_train_labels.append(row[1])\n",
    "#print(jdres_train_data)\n",
    "#print(len(jdres_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(jdres_train_data))\n",
    "print(len(jdres_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(jdres_train_data,columns=['filecontent'])\n",
    "df2 = pd.DataFrame(jdres_train_labels,columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(jdres_train_data[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(jdres_train_labels)\n",
    "encoded_labels = encoder.transform(jdres_train_labels)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "labels = to_categorical(encoded_labels,num_classes=4)\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31679"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(jdres_train_data)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(jdres_train_data)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14590   166   121 ...,  1659   275   161]\n",
      " [ 5912   754  4115 ...,     0     0     0]\n",
      " [10355  2964 10355 ...,     0     0     0]\n",
      " ..., \n",
      " [  285   349 31629 ...,     0     0     0]\n",
      " [ 2574 14586  2574 ...,     0     0     0]\n",
      " [ 5228  3864  3654 ...,     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 250 words\n",
    "max_length = 1000\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (600, 1000)\n",
      "Shape of label tensor: (600, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', padded_docs.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(padded_docs.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "padded_docs = padded_docs[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#loading glove\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('/home/shabna/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "\n",
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D,GlobalMaxPooling1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size,100, weights=[embedding_matrix], input_length=1000, trainable='true')\n",
    "    model.add(e)\n",
    "    model.add(Conv1D(128,5, activation='relu',name='l1'))\n",
    "    model.add(MaxPooling1D(pool_size=5,name='l2'))\n",
    "    model.add(Conv1D(128, 5, activation='relu',name='l3'))\n",
    "    model.add(GlobalMaxPooling1D(name='l4'))\n",
    "   \n",
    "    model.add(Dense(12, activation='sigmoid',name='l5'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax',name='l6'))\n",
    "    #adam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         3167900   \n",
      "_________________________________________________________________\n",
      "l1 (Conv1D)                  (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "l2 (MaxPooling1D)            (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "l3 (Conv1D)                  (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "l4 (GlobalMaxPooling1D)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "l5 (Dense)                   (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "l6 (Dense)                   (None, 4)                 52        \n",
      "=================================================================\n",
      "Total params: 3,315,676\n",
      "Trainable params: 3,315,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = Model(embedding_matrix, preds)\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum, batch_size=batch_size, epochs=epochs,optimizer=optimizer)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "    grid_result = grid.fit(X_train, y_train,validation_data=(X_val,y_val))\n",
    "    \n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"/home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=\"True\", mode=\"max\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :num of fold\n",
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "300/384 [======================>.......] - ETA: 10s - loss: 1.4913 - acc: 0.2600Epoch 00001: val_acc improved from -inf to 0.23958, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 48s 124ms/step - loss: 1.4728 - acc: 0.2708 - val_loss: 1.4209 - val_acc: 0.2396\n",
      "Epoch 2/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 1.3548 - acc: 0.3133 Epoch 00002: val_acc improved from 0.23958 to 0.39583, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 1.3479 - acc: 0.3333 - val_loss: 1.3552 - val_acc: 0.3958\n",
      "Epoch 3/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 1.3167 - acc: 0.3833 Epoch 00003: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 1.3020 - acc: 0.3984 - val_loss: 1.3371 - val_acc: 0.3125\n",
      "Epoch 4/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 1.2442 - acc: 0.6033 Epoch 00004: val_acc improved from 0.39583 to 0.69792, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 1.2438 - acc: 0.6328 - val_loss: 1.2707 - val_acc: 0.6979\n",
      "Epoch 5/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 1.1599 - acc: 0.7767 Epoch 00005: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 1.1559 - acc: 0.7578 - val_loss: 1.2463 - val_acc: 0.4896\n",
      "Epoch 6/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 1.0956 - acc: 0.7367 Epoch 00006: val_acc improved from 0.69792 to 0.80208, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 1.0919 - acc: 0.7474 - val_loss: 1.1858 - val_acc: 0.8021\n",
      "Epoch 7/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 1.0652 - acc: 0.7467 Epoch 00007: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 1.0673 - acc: 0.7292 - val_loss: 1.1277 - val_acc: 0.7604\n",
      "Epoch 8/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 1.0184 - acc: 0.7867 Epoch 00008: val_acc improved from 0.80208 to 0.85417, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.9946 - acc: 0.8073 - val_loss: 1.0304 - val_acc: 0.8542\n",
      "Epoch 9/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.9250 - acc: 0.8067 Epoch 00009: val_acc did not improve\n",
      "384/384 [==============================] - 29s 75ms/step - loss: 0.9189 - acc: 0.8073 - val_loss: 0.9977 - val_acc: 0.8333\n",
      "Epoch 10/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.8229 - acc: 0.8433 Epoch 00010: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.8205 - acc: 0.8490 - val_loss: 0.9525 - val_acc: 0.8438\n",
      "Epoch 11/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.7995 - acc: 0.8567 Epoch 00011: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.7854 - acc: 0.8724 - val_loss: 0.8888 - val_acc: 0.8542\n",
      "Epoch 12/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.7395 - acc: 0.8833 Epoch 00012: val_acc did not improve\n",
      "384/384 [==============================] - 29s 77ms/step - loss: 0.7429 - acc: 0.8776 - val_loss: 0.8761 - val_acc: 0.8542\n",
      "Epoch 13/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.6751 - acc: 0.9300 Epoch 00013: val_acc improved from 0.85417 to 0.88542, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 31s 81ms/step - loss: 0.6789 - acc: 0.9219 - val_loss: 0.8401 - val_acc: 0.8854\n",
      "Epoch 14/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.6781 - acc: 0.8833 Epoch 00014: val_acc improved from 0.88542 to 0.89583, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 31s 80ms/step - loss: 0.6579 - acc: 0.8984 - val_loss: 0.8162 - val_acc: 0.8958\n",
      "Epoch 15/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.6307 - acc: 0.9200 Epoch 00015: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.6335 - acc: 0.9271 - val_loss: 0.7689 - val_acc: 0.8854\n",
      "Epoch 16/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.6070 - acc: 0.9100 Epoch 00016: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.5951 - acc: 0.9141 - val_loss: 0.7387 - val_acc: 0.8750\n",
      "Epoch 17/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.5792 - acc: 0.9200 Epoch 00017: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.5816 - acc: 0.9219 - val_loss: 0.7164 - val_acc: 0.8854\n",
      "Epoch 18/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.5388 - acc: 0.9467 Epoch 00018: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.5416 - acc: 0.9453 - val_loss: 0.6962 - val_acc: 0.8854\n",
      "Epoch 19/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.5181 - acc: 0.9467 Epoch 00019: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.5122 - acc: 0.9453 - val_loss: 0.6922 - val_acc: 0.8750\n",
      "Epoch 20/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.5188 - acc: 0.9200 Epoch 00020: val_acc improved from 0.89583 to 0.90625, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.5162 - acc: 0.9297 - val_loss: 0.6643 - val_acc: 0.9062\n",
      "Epoch 21/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4936 - acc: 0.9300 Epoch 00021: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4913 - acc: 0.9297 - val_loss: 0.6680 - val_acc: 0.8854\n",
      "Epoch 22/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4790 - acc: 0.9667 Epoch 00022: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4753 - acc: 0.9635 - val_loss: 0.6592 - val_acc: 0.8958\n",
      "Epoch 23/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4755 - acc: 0.9600 Epoch 00023: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.4698 - acc: 0.9609 - val_loss: 0.6437 - val_acc: 0.8958\n",
      "Epoch 24/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4681 - acc: 0.9600 Epoch 00024: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4759 - acc: 0.9479 - val_loss: 0.6354 - val_acc: 0.8958\n",
      "Epoch 25/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4334 - acc: 0.9667 Epoch 00025: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.4431 - acc: 0.9583 - val_loss: 0.6273 - val_acc: 0.8958\n",
      "Epoch 26/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4613 - acc: 0.9433 Epoch 00026: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4601 - acc: 0.9375 - val_loss: 0.6215 - val_acc: 0.9062\n",
      "Epoch 27/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4409 - acc: 0.9700 Epoch 00027: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4303 - acc: 0.9740 - val_loss: 0.6275 - val_acc: 0.9062\n",
      "Epoch 28/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4316 - acc: 0.9600 Epoch 00028: val_acc improved from 0.90625 to 0.92708, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.4383 - acc: 0.9609 - val_loss: 0.6101 - val_acc: 0.9271\n",
      "Epoch 29/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4376 - acc: 0.9633 Epoch 00029: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.4436 - acc: 0.9557 - val_loss: 0.6106 - val_acc: 0.9062\n",
      "Epoch 30/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4350 - acc: 0.9500 Epoch 00030: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4388 - acc: 0.9453 - val_loss: 0.6033 - val_acc: 0.9167\n",
      "Epoch 31/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4348 - acc: 0.9733 Epoch 00031: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4394 - acc: 0.9714 - val_loss: 0.5971 - val_acc: 0.9167\n",
      "Epoch 32/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4000 - acc: 0.9800 Epoch 00032: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3928 - acc: 0.9792 - val_loss: 0.6000 - val_acc: 0.9062\n",
      "Epoch 33/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3846 - acc: 0.9633 Epoch 00033: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3856 - acc: 0.9661 - val_loss: 0.5940 - val_acc: 0.9062\n",
      "Epoch 34/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.4046 - acc: 0.9667 Epoch 00034: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3991 - acc: 0.9688 - val_loss: 0.5786 - val_acc: 0.9167\n",
      "Epoch 35/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3763 - acc: 0.9700 Epoch 00035: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3837 - acc: 0.9688 - val_loss: 0.5753 - val_acc: 0.9062\n",
      "Epoch 36/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3964 - acc: 0.9533 Epoch 00036: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.3895 - acc: 0.9583 - val_loss: 0.5772 - val_acc: 0.9062\n",
      "Epoch 37/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3667 - acc: 0.9767 Epoch 00037: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3684 - acc: 0.9740 - val_loss: 0.5670 - val_acc: 0.9167\n",
      "Epoch 38/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3979 - acc: 0.9833 Epoch 00038: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.4017 - acc: 0.9766 - val_loss: 0.5595 - val_acc: 0.9167\n",
      "Epoch 39/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3541 - acc: 0.9833 Epoch 00039: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3608 - acc: 0.9740 - val_loss: 0.5529 - val_acc: 0.9167\n",
      "Epoch 40/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3652 - acc: 0.9867 Epoch 00040: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3693 - acc: 0.9766 - val_loss: 0.5460 - val_acc: 0.9167\n",
      "Epoch 41/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3625 - acc: 0.9700 Epoch 00041: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.3573 - acc: 0.9714 - val_loss: 0.5419 - val_acc: 0.9167\n",
      "Epoch 42/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3827 - acc: 0.9633 Epoch 00042: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3814 - acc: 0.9661 - val_loss: 0.5362 - val_acc: 0.9167\n",
      "Epoch 43/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3596 - acc: 0.9733 Epoch 00043: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.3569 - acc: 0.9792 - val_loss: 0.5300 - val_acc: 0.9062\n",
      "Epoch 44/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.3407 - acc: 0.9867 Epoch 00044: val_acc did not improve\n",
      "384/384 [==============================] - 29s 76ms/step - loss: 0.3429 - acc: 0.9844 - val_loss: 0.5225 - val_acc: 0.9167\n",
      "Epoch 45/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.3380 - acc: 0.9833 Epoch 00045: val_acc did not improve\n",
      "384/384 [==============================] - 29s 76ms/step - loss: 0.3274 - acc: 0.9844 - val_loss: 0.5020 - val_acc: 0.9062\n",
      "Epoch 46/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3309 - acc: 0.9833 Epoch 00046: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.3231 - acc: 0.9844 - val_loss: 0.5012 - val_acc: 0.9062\n",
      "Epoch 47/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3287 - acc: 0.9867 Epoch 00047: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3192 - acc: 0.9870 - val_loss: 0.4858 - val_acc: 0.9062\n",
      "Epoch 48/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2950 - acc: 0.9933 Epoch 00048: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2939 - acc: 0.9922 - val_loss: 0.4698 - val_acc: 0.8958\n",
      "Epoch 49/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2827 - acc: 0.9867 Epoch 00049: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2820 - acc: 0.9896 - val_loss: 0.4666 - val_acc: 0.9062\n",
      "Epoch 50/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2742 - acc: 0.9933 Epoch 00050: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.2801 - acc: 0.9948 - val_loss: 0.4719 - val_acc: 0.8958\n",
      "2 :num of fold\n",
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3471 - acc: 0.9700 Epoch 00001: val_acc improved from 0.92708 to 1.00000, saving model to /home/shabna/Desktop/example_codes/weights_3_2.best.hdf5\n",
      "384/384 [==============================] - 31s 80ms/step - loss: 0.3418 - acc: 0.9714 - val_loss: 0.2185 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3141 - acc: 0.9733 Epoch 00002: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.3177 - acc: 0.9740 - val_loss: 0.2086 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.3093 - acc: 0.9700 Epoch 00003: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.2888 - acc: 0.9766 - val_loss: 0.2023 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2575 - acc: 0.9900 Epoch 00004: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2665 - acc: 0.9870 - val_loss: 0.1977 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2676 - acc: 0.9967 Epoch 00005: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.2557 - acc: 0.9948 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2538 - acc: 0.9867 Epoch 00006: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.2577 - acc: 0.9844 - val_loss: 0.1889 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2561 - acc: 0.9900 Epoch 00007: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2537 - acc: 0.9896 - val_loss: 0.1849 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2380 - acc: 0.9900 Epoch 00008: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2400 - acc: 0.9870 - val_loss: 0.1814 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2253 - acc: 0.9933 Epoch 00009: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2336 - acc: 0.9922 - val_loss: 0.1784 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2448 - acc: 0.9833 Epoch 00010: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2500 - acc: 0.9844 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2385 - acc: 0.9833 Epoch 00011: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2313 - acc: 0.9844 - val_loss: 0.1717 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2297 - acc: 0.9833 Epoch 00012: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2245 - acc: 0.9870 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.2211 - acc: 0.9900 Epoch 00013: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.2167 - acc: 0.9896 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2442 - acc: 0.9900 Epoch 00014: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2318 - acc: 0.9922 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2123 - acc: 0.9933 Epoch 00015: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2080 - acc: 0.9948 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2097 - acc: 0.9900 Epoch 00016: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2168 - acc: 0.9870 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1973 - acc: 1.0000 Epoch 00017: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2037 - acc: 0.9922 - val_loss: 0.1554 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2298 - acc: 0.9833 Epoch 00018: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2423 - acc: 0.9844 - val_loss: 0.1528 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2259 - acc: 0.9867 Epoch 00019: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2158 - acc: 0.9870 - val_loss: 0.1505 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2312 - acc: 0.9867 Epoch 00020: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.2346 - acc: 0.9844 - val_loss: 0.1495 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.2170 - acc: 0.9867 Epoch 00021: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.2129 - acc: 0.9870 - val_loss: 0.1441 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1740 - acc: 0.9933 Epoch 00022: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1847 - acc: 0.9896 - val_loss: 0.1353 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1985 - acc: 0.9867 Epoch 00023: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1900 - acc: 0.9896 - val_loss: 0.1282 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1832 - acc: 0.9867 Epoch 00024: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1824 - acc: 0.9896 - val_loss: 0.1260 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1513 - acc: 1.0000 Epoch 00025: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1707 - acc: 0.9948 - val_loss: 0.1225 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1579 - acc: 0.9967 Epoch 00026: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1580 - acc: 0.9948 - val_loss: 0.1206 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1657 - acc: 0.9933 Epoch 00027: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1652 - acc: 0.9948 - val_loss: 0.1174 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1556 - acc: 0.9967 Epoch 00028: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1571 - acc: 0.9948 - val_loss: 0.1159 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1625 - acc: 0.9933 Epoch 00029: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1580 - acc: 0.9948 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1674 - acc: 1.0000 Epoch 00030: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1714 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1482 - acc: 0.9933 Epoch 00031: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1557 - acc: 0.9896 - val_loss: 0.1108 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1387 - acc: 0.9967 Epoch 00032: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1429 - acc: 0.9948 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1560 - acc: 0.9900 Epoch 00033: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1493 - acc: 0.9922 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1352 - acc: 1.0000 Epoch 00034: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1401 - acc: 0.9974 - val_loss: 0.1086 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1433 - acc: 0.9967 Epoch 00035: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1439 - acc: 0.9974 - val_loss: 0.1038 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1559 - acc: 1.0000 Epoch 00036: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1549 - acc: 0.9974 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1411 - acc: 1.0000 Epoch 00037: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1408 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1433 - acc: 0.9933 Epoch 00038: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1378 - acc: 0.9948 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1600 - acc: 0.9933 Epoch 00039: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1497 - acc: 0.9948 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1451 - acc: 0.9933 Epoch 00040: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1436 - acc: 0.9922 - val_loss: 0.0965 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1350 - acc: 0.9933 Epoch 00041: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1346 - acc: 0.9896 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1379 - acc: 0.9967 Epoch 00042: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1358 - acc: 0.9974 - val_loss: 0.0927 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1283 - acc: 0.9967 Epoch 00043: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1249 - acc: 0.9974 - val_loss: 0.0910 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1280 - acc: 1.0000 Epoch 00044: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1249 - acc: 1.0000 - val_loss: 0.0895 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1338 - acc: 1.0000 Epoch 00045: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1309 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1254 - acc: 0.9967 Epoch 00046: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1237 - acc: 0.9948 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1151 - acc: 0.9967 Epoch 00047: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1171 - acc: 0.9974 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1232 - acc: 0.9900 Epoch 00048: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1229 - acc: 0.9896 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1237 - acc: 0.9967 Epoch 00049: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1266 - acc: 0.9974 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1289 - acc: 1.0000 Epoch 00050: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1261 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "3 :num of fold\n",
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1271 - acc: 1.0000 Epoch 00001: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1243 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1233 - acc: 1.0000 Epoch 00002: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1198 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1374 - acc: 0.9933 Epoch 00003: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1380 - acc: 0.9922 - val_loss: 0.0818 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1085 - acc: 1.0000 Epoch 00004: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1089 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1178 - acc: 0.9967 Epoch 00005: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1185 - acc: 0.9974 - val_loss: 0.0797 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1117 - acc: 1.0000 Epoch 00006: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1091 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1167 - acc: 0.9967 Epoch 00007: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1123 - acc: 0.9974 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1153 - acc: 1.0000 Epoch 00008: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1128 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1178 - acc: 0.9900 Epoch 00009: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1155 - acc: 0.9922 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1298 - acc: 0.9933 Epoch 00010: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1264 - acc: 0.9922 - val_loss: 0.0748 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1105 - acc: 1.0000 Epoch 00011: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1101 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1073 - acc: 0.9967 Epoch 00012: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1061 - acc: 0.9974 - val_loss: 0.0730 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1043 - acc: 1.0000 Epoch 00013: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1080 - acc: 0.9933 Epoch 00014: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1095 - acc: 0.9922 - val_loss: 0.0713 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1044 - acc: 1.0000 Epoch 00015: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 0.0704 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1027 - acc: 1.0000 Epoch 00016: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1052 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1014 - acc: 0.9967 Epoch 00017: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1009 - acc: 0.9974 - val_loss: 0.0688 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1115 - acc: 1.0000 Epoch 00018: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1165 - acc: 0.9948 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1019 - acc: 1.0000 Epoch 00019: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0972 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0999 - acc: 1.0000 Epoch 00020: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0979 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1056 - acc: 1.0000 Epoch 00021: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1051 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1058 - acc: 0.9967 Epoch 00022: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1105 - acc: 0.9948 - val_loss: 0.0648 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1045 - acc: 1.0000 Epoch 00023: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0901 - acc: 1.0000 Epoch 00024: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0935 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0950 - acc: 1.0000 Epoch 00025: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0922 - acc: 0.9974 - val_loss: 0.0626 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0977 - acc: 1.0000 Epoch 00026: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1014 - acc: 0.9974 - val_loss: 0.0620 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1135 - acc: 0.9900 Epoch 00027: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1108 - acc: 0.9922 - val_loss: 0.0613 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1027 - acc: 0.9933 Epoch 00028: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1023 - acc: 0.9948 - val_loss: 0.0606 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1013 - acc: 0.9933 Epoch 00029: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0978 - acc: 0.9948 - val_loss: 0.0600 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.1055 - acc: 0.9900 Epoch 00030: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.1058 - acc: 0.9922 - val_loss: 0.0593 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0899 - acc: 0.9967 Epoch 00031: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0914 - acc: 0.9974 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1049 - acc: 0.9933 Epoch 00032: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1090 - acc: 0.9896 - val_loss: 0.0580 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1021 - acc: 0.9967 Epoch 00033: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.1051 - acc: 0.9948 - val_loss: 0.0574 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0910 - acc: 1.0000 Epoch 00034: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.1004 - acc: 0.9974 - val_loss: 0.0568 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.1010 - acc: 0.9967 Epoch 00035: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0977 - acc: 0.9974 - val_loss: 0.0562 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0903 - acc: 0.9967 Epoch 00036: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0887 - acc: 0.9974 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0997 - acc: 1.0000 Epoch 00037: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0930 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0805 - acc: 1.0000 Epoch 00038: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0776 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0974 - acc: 0.9967 Epoch 00039: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0998 - acc: 0.9948 - val_loss: 0.0539 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0978 - acc: 1.0000 Epoch 00040: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0924 - acc: 1.0000 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0959 - acc: 0.9933 Epoch 00041: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0927 - acc: 0.9948 - val_loss: 0.0528 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0930 - acc: 0.9967 Epoch 00042: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0858 - acc: 0.9974 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0841 - acc: 0.9967 Epoch 00043: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0887 - acc: 0.9948 - val_loss: 0.0517 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0815 - acc: 0.9967 Epoch 00044: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0814 - acc: 0.9974 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0735 - acc: 0.9967 Epoch 00045: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0754 - acc: 0.9974 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0789 - acc: 0.9967 Epoch 00046: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0829 - acc: 0.9974 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0865 - acc: 1.0000 Epoch 00047: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0818 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0963 - acc: 0.9967 Epoch 00048: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0948 - acc: 0.9974 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0839 - acc: 1.0000 Epoch 00049: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0854 - acc: 0.9974 - val_loss: 0.0486 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0915 - acc: 1.0000 Epoch 00050: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0968 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "4 :num of fold\n",
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0778 - acc: 1.0000 Epoch 00001: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0917 - acc: 0.9974 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0796 - acc: 1.0000 Epoch 00002: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0796 - acc: 0.9974 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0994 - acc: 0.9933 Epoch 00003: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0943 - acc: 0.9948 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0867 - acc: 0.9967 Epoch 00004: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0842 - acc: 0.9974 - val_loss: 0.0434 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0745 - acc: 1.0000 Epoch 00005: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0764 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0782 - acc: 1.0000 Epoch 00006: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0784 - acc: 0.9974 - val_loss: 0.0426 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0867 - acc: 1.0000 Epoch 00007: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0864 - acc: 0.9974 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0838 - acc: 0.9967 Epoch 00008: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0820 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 1.0000\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0805 - acc: 1.0000 Epoch 00009: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0815 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0897 - acc: 0.9967 Epoch 00010: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0882 - acc: 0.9974 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0628 - acc: 1.0000 Epoch 00011: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0678 - acc: 1.0000 Epoch 00012: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0742 - acc: 0.9974 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0794 - acc: 1.0000 Epoch 00013: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0778 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0745 - acc: 0.9967 Epoch 00014: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0790 - acc: 0.9974 - val_loss: 0.0393 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0842 - acc: 1.0000 Epoch 00015: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0884 - acc: 0.9974 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0792 - acc: 0.9967 Epoch 00016: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0834 - acc: 0.9974 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0760 - acc: 1.0000 Epoch 00017: val_acc did not improve\n",
      "384/384 [==============================] - 29s 77ms/step - loss: 0.0821 - acc: 0.9974 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0717 - acc: 1.0000 Epoch 00018: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0781 - acc: 0.9974 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0867 - acc: 0.9967 Epoch 00019: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0827 - acc: 0.9974 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0766 - acc: 1.0000 Epoch 00020: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0736 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0643 - acc: 1.0000 Epoch 00021: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0684 - acc: 0.9948 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0711 - acc: 0.9967 Epoch 00022: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0662 - acc: 0.9974 - val_loss: 0.0365 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0760 - acc: 1.0000 Epoch 00023: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0735 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0683 - acc: 0.9967 Epoch 00024: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0664 - acc: 0.9974 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0874 - acc: 0.9967 Epoch 00025: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0799 - acc: 0.9948 - val_loss: 0.0355 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0850 - acc: 0.9900 Epoch 00026: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0863 - acc: 0.9896 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0703 - acc: 1.0000 Epoch 00027: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0691 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0643 - acc: 1.0000 Epoch 00028: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0637 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0724 - acc: 0.9933 Epoch 00029: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0731 - acc: 0.9948 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0753 - acc: 1.0000 Epoch 00030: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0694 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0680 - acc: 1.0000 Epoch 00031: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0639 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0716 - acc: 0.9933 Epoch 00032: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0722 - acc: 0.9922 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0593 - acc: 0.9967 Epoch 00033: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0601 - acc: 0.9974 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0659 - acc: 0.9967 Epoch 00034: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0676 - acc: 0.9974 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0658 - acc: 1.0000 Epoch 00035: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0704 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0655 - acc: 1.0000 Epoch 00036: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0640 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0662 - acc: 0.9933 Epoch 00037: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0649 - acc: 0.9948 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0689 - acc: 1.0000 Epoch 00038: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0699 - acc: 0.9967 Epoch 00039: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0813 - acc: 0.9922 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0597 - acc: 0.9967 Epoch 00040: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0574 - acc: 0.9974 - val_loss: 0.0311 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0747 - acc: 0.9967 Epoch 00041: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0752 - acc: 0.9974 - val_loss: 0.0308 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0749 - acc: 0.9933 Epoch 00042: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0718 - acc: 0.9948 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0623 - acc: 0.9967 Epoch 00043: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0596 - acc: 0.9974 - val_loss: 0.0303 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0729 - acc: 0.9967 Epoch 00044: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0689 - acc: 0.9974 - val_loss: 0.0300 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0692 - acc: 1.0000 Epoch 00045: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0688 - acc: 0.9974 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0703 - acc: 0.9933 Epoch 00046: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0715 - acc: 0.9922 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0718 - acc: 0.9967 Epoch 00047: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0690 - acc: 0.9974 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0647 - acc: 1.0000 Epoch 00048: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0656 - acc: 0.9933 Epoch 00049: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0649 - acc: 0.9948 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0620 - acc: 0.9933 Epoch 00050: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0596 - acc: 0.9948 - val_loss: 0.0285 - val_acc: 1.0000\n",
      "5 :num of fold\n",
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0664 - acc: 0.9967 Epoch 00001: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0735 - acc: 0.9948 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0741 - acc: 0.9933 Epoch 00002: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0690 - acc: 0.9948 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0724 - acc: 0.9933 Epoch 00003: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0679 - acc: 0.9922 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0529 - acc: 1.0000 Epoch 00004: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0539 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0488 - acc: 1.0000 Epoch 00005: val_acc did not improve\n",
      "384/384 [==============================] - 29s 77ms/step - loss: 0.0521 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0628 - acc: 1.0000 Epoch 00006: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0676 - acc: 0.9974 - val_loss: 0.0259 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0616 - acc: 0.9967 Epoch 00007: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0601 - acc: 0.9974 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0556 - acc: 1.0000 Epoch 00008: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0533 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0669 - acc: 0.9967 Epoch 00009: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0646 - acc: 0.9974 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0582 - acc: 0.9967 Epoch 00010: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0640 - acc: 0.9948 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0508 - acc: 1.0000 Epoch 00011: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0585 - acc: 0.9974 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0668 - acc: 1.0000 Epoch 00012: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0684 - acc: 0.9974 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0675 - acc: 0.9967 Epoch 00013: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0647 - acc: 0.9974 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0546 - acc: 0.9933 Epoch 00014: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0549 - acc: 0.9948 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0630 - acc: 0.9967 Epoch 00015: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0642 - acc: 0.9974 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0515 - acc: 1.0000 Epoch 00016: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0489 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0578 - acc: 1.0000 Epoch 00017: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0612 - acc: 0.9974 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0564 - acc: 1.0000 Epoch 00018: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0555 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0522 - acc: 1.0000 Epoch 00019: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0516 - acc: 0.9974 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0711 - acc: 0.9933 Epoch 00020: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0647 - acc: 0.9948 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0633 - acc: 0.9933 Epoch 00021: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0639 - acc: 0.9922 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0650 - acc: 0.9967 Epoch 00022: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0599 - acc: 0.9974 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0625 - acc: 0.9933 Epoch 00023: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0607 - acc: 0.9922 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0695 - acc: 1.0000 Epoch 00024: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0701 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0546 - acc: 1.0000 Epoch 00025: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0582 - acc: 0.9974 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0627 - acc: 0.9967 Epoch 00026: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0605 - acc: 0.9974 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0575 - acc: 1.0000 Epoch 00027: val_acc did not improve\n",
      "384/384 [==============================] - 29s 77ms/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0625 - acc: 0.9933 Epoch 00028: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0610 - acc: 0.9948 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0553 - acc: 1.0000 Epoch 00029: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0580 - acc: 0.9974 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0632 - acc: 0.9933 Epoch 00030: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0639 - acc: 0.9948 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0709 - acc: 0.9967 Epoch 00031: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0653 - acc: 0.9974 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0508 - acc: 0.9933 Epoch 00032: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0521 - acc: 0.9922 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0484 - acc: 1.0000 Epoch 00033: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0470 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0555 - acc: 0.9967 Epoch 00034: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0532 - acc: 0.9974 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0525 - acc: 0.9933 Epoch 00035: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0510 - acc: 0.9948 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0438 - acc: 1.0000 Epoch 00036: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0629 - acc: 0.9967 Epoch 00037: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0605 - acc: 0.9974 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0575 - acc: 0.9967 Epoch 00038: val_acc did not improve\n",
      "384/384 [==============================] - 29s 77ms/step - loss: 0.0572 - acc: 0.9974 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0567 - acc: 0.9933 Epoch 00039: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0600 - acc: 0.9922 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0518 - acc: 0.9967 Epoch 00040: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0598 - acc: 0.9922 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0572 - acc: 0.9933 Epoch 00041: val_acc did not improve\n",
      "384/384 [==============================] - 30s 78ms/step - loss: 0.0555 - acc: 0.9948 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0415 - acc: 1.0000 Epoch 00042: val_acc did not improve\n",
      "384/384 [==============================] - 30s 77ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0576 - acc: 0.9967 Epoch 00043: val_acc did not improve\n",
      "384/384 [==============================] - 30s 79ms/step - loss: 0.0623 - acc: 0.9974 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "300/384 [======================>.......] - ETA: 6s - loss: 0.0402 - acc: 1.0000 Epoch 00044: val_acc did not improve\n",
      "384/384 [==============================] - 28s 74ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "300/384 [======================>.......] - ETA: 3s - loss: 0.0590 - acc: 0.9900Epoch 00045: val_acc did not improve\n",
      "384/384 [==============================] - 16s 40ms/step - loss: 0.0579 - acc: 0.9896 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "300/384 [======================>.......] - ETA: 5s - loss: 0.0619 - acc: 0.9867 Epoch 00046: val_acc did not improve\n",
      "384/384 [==============================] - 25s 65ms/step - loss: 0.0610 - acc: 0.9896 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "300/384 [======================>.......] - ETA: 3s - loss: 0.0458 - acc: 1.0000Epoch 00047: val_acc did not improve\n",
      "384/384 [==============================] - 15s 40ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "300/384 [======================>.......] - ETA: 3s - loss: 0.0499 - acc: 0.9967Epoch 00048: val_acc did not improve\n",
      "384/384 [==============================] - 15s 40ms/step - loss: 0.0486 - acc: 0.9974 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "300/384 [======================>.......] - ETA: 3s - loss: 0.0509 - acc: 0.9967Epoch 00049: val_acc did not improve\n",
      "384/384 [==============================] - 15s 40ms/step - loss: 0.0582 - acc: 0.9948 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "300/384 [======================>.......] - ETA: 3s - loss: 0.0669 - acc: 0.9933Epoch 00050: val_acc did not improve\n",
      "384/384 [==============================] - 15s 40ms/step - loss: 0.0625 - acc: 0.9948 - val_loss: 0.0184 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "XX_train, X_test, yy_train, y_test = train_test_split(padded_docs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "i=1\n",
    "for train_index, test_index in kf.split(XX_train):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(i,\":num of fold\")\n",
    "\n",
    "    X_train, X_val = XX_train[train_index], XX_train[test_index]\n",
    "    y_train, y_val = yy_train[train_index], yy_train[test_index]\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val,y_val) ,epochs=50, batch_size=100, verbose=1, callbacks=callbacks_list)\n",
    "   \n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"weights_3_2.best.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file = 'models_3_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "p = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 2s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35735614101092023, 0.95000000397364304]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2635170804957549, 0.984375]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_index = {'hr':0 ,'marketing':1, 'other':2, 'seo':3}\n",
    "target_name = [t for t in labels_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         hr       0.97      0.97      0.97        29\n",
      "  marketing       1.00      0.86      0.93        37\n",
      "      other       0.84      1.00      0.91        21\n",
      "        seo       0.97      1.00      0.99        33\n",
      "\n",
      "avg / total       0.96      0.95      0.95       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1),y_pred,target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  0  1  0]\n",
      " [ 1 32  3  1]\n",
      " [ 0  0 21  0]\n",
      " [ 0  0  0 33]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_test,axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(2, 1)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(0, 1)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "for i, item in enumerate (X_test):\n",
    "    item= item.reshape(1, 1000)\n",
    "    #print (item.shape)\n",
    "    classes=model.predict(item)\n",
    "    p=(argmax(classes),argmax(y_test[i]))\n",
    "    #print(p)\n",
    "    if (argmax(classes)!=argmax(y_test[i])):\n",
    "        print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1000)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1000)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7166  6295 18068 ...,     0     0     0]\n",
      " [  139  5543   484 ...,     0     0     0]\n",
      " [   47    32 10290 ...,     0     0     0]\n",
      " ..., \n",
      " [  139 19015 11794 ...,     0     0     0]\n",
      " [ 1392   121   139 ...,     0     0     0]\n",
      " [13212    29 26119 ...,     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['personal information nationality indian email imransidihotmailcom mobile 65 8698 3868 languages english fluent hindi native french elementary summary global management student four years experience application technology management outsourcing imran’s skills technofunctional expert developed groomed moreover providing remote dedicated support services premier clients high pressure environments imran able hone excellent project management skills education 20152016 graduate april 2016 master business administration contemporary marketing management sp jain school global management singapore sydney dubai 2007–2011 bachelor technology electronics telecommunication mpstme – nmims university mumbai  india linkedin https wwwlinkedincominimransidi photo  delete box “paste over” please sidi imran professional experience accenture mumbai  melbourne july 2011 – may 2015 software engineering sr analyst  operation client – one largest mining company’s world ‘1 internet presence’ sharepoint 2010 based front end website client july 2011 – may 2015 held key responsibility engage vip clients ensure high quality deliverables managed technical requirement website publishing activities announcements coordinated various 3rd party vendors microsoft akamai ibm coached client’s corporate communication team efficient use sharepoint tools created content authoring guide search engine optimization done integrating various third party services streamlined resources shift planning – saved sgd 50 000 developed implemented team strategies reduce incident backlogs promoted twice within 2 years 6 months early promotion servicenow service management tool nov 2013 – may 2015 worked crossfunctional team assisting product customizations managed transition operations  service management legacy tools servicenow worked shift lead managed team support client users across globe created high level service documents facilitated change management process process communication champion delivery unit gptw initiatives resources industry circles apr 2014 – may 2015 initiated idea implemented internal social media page industry group successfully implemented multiple campaigns events within industry group additional information applied learning project fetchizi mobile app singapore create business plan including marketing financial models pitch investment create multiple digital campaigns various social media platforms launch app generate affiliate marketing leads create sales guidelines merchant onboarding applied research project mrs fields cookies  cookieman sydney field study mrs fieldss cookie – perception analysis consumer behavior research 2015 understand customer perceptions cookies made dough sourced locally australia well dough imported us compare analyze whether difference two result changes consumer demand awards  recognitions awarded “second place – entrepreneur sydney” sp jain school global management 2015 awarded “second place – case analysis competition dubai” sp jain school global management 2015 awarded “accenture celebrates excellence awards – gold standard – team category” accenture 2014 awarded “the avanade orange award delivery excellence team” avanade 2014 awarded “the avanade orange award best gptw team” avanade 2014 awarded “the outperformer – merlion” accenture 2012 awarded “all india winner vodafone race fame” mtv 2012 awarded “amaron national karting champion team category  college ” amaron  meco motorsports 2012 ambassador nmims university member department advisory board board studies 2011 professional qualifications skills mcts microsoft sharepoint 2010 application development mcts certified apr 2012 itil v3 foundation itil certified nov 2011 servicenow admin itsm vb macros microsoft office advanced proficiency using applications interest founder member placom cell student placement coordinator batch 2010  2011 brought 4 companies individually placements achieved 100 placements batch size 300 students founder member college fest sattva supervisor sattva 2009 2010 2011 founder soleorganizer sonic boom 10 20 inter college karting event gold medalist running basketball volley ball mba olympics 2016 sport competition held ntu participants mba candidate nus smu sp jain essec business schools mailto imransidihotmailcom https wwwlinkedincominimransidi9898a718']\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "\n",
    "parsedPDF = parser.from_file(\"/home/shabna/Desktop/example_codes/new_sample/level3/nontech/marketing/Imran_Sidi_Singapore_3.10_yrs.pdf\")\n",
    "parsedPDF = parser.from_file(\"/home/shabna/Desktop/example_codes/new_sample/level3/nontech/hr/ShrutiSharma[8_0].doc\")\n",
    "\n",
    "contents=[clean_doc(parsedPDF['content'])]\n",
    "            \n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prpInput(pp):\n",
    "    tx = Tokenizer()\n",
    "    tx.fit_on_texts(pp)\n",
    "    vocab_size = len(tx.word_index)+1\n",
    "    encoded_doc = tx.texts_to_sequences(pp)\n",
    "    max_length = 1000\n",
    "    padded_docs = pad_sequences(encoded_doc, maxlen=max_length, padding='post')\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat=prpInput(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prd = model.predict(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'hr', 1: 'marketing', 2: 'other', 3: 'seo'}\n"
     ]
    }
   ],
   "source": [
    "#labels_index = {'marketing':0 ,'hr':1, 'seo':2, 'other':3}\n",
    "rev_lable_index = {}\n",
    "for key in labels_index:\n",
    "    rev_lable_index[labels_index[key]] = key\n",
    "print(rev_lable_index)\n",
    "def result(prd,contents):\n",
    "    y_classes = prd.argmax(axis=-1)\n",
    "    print(len(y_classes))\n",
    "    lx=[]\n",
    "    for idx,lb in enumerate(y_classes):\n",
    "        lx.append([contents[idx],rev_lable_index[lb]])\n",
    "    return lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['personal information nationality indian email imransidihotmailcom mobile 65 8698 3868 languages english fluent hindi native french elementary summary global management student four years experience application technology management outsourcing imran’s skills technofunctional expert developed groomed moreover providing remote dedicated support services premier clients high pressure environments imran able hone excellent project management skills education 20152016 graduate april 2016 master business administration contemporary marketing management sp jain school global management singapore sydney dubai 2007–2011 bachelor technology electronics telecommunication mpstme – nmims university mumbai  india linkedin https wwwlinkedincominimransidi photo  delete box “paste over” please sidi imran professional experience accenture mumbai  melbourne july 2011 – may 2015 software engineering sr analyst  operation client – one largest mining company’s world ‘1 internet presence’ sharepoint 2010 based front end website client july 2011 – may 2015 held key responsibility engage vip clients ensure high quality deliverables managed technical requirement website publishing activities announcements coordinated various 3rd party vendors microsoft akamai ibm coached client’s corporate communication team efficient use sharepoint tools created content authoring guide search engine optimization done integrating various third party services streamlined resources shift planning – saved sgd 50 000 developed implemented team strategies reduce incident backlogs promoted twice within 2 years 6 months early promotion servicenow service management tool nov 2013 – may 2015 worked crossfunctional team assisting product customizations managed transition operations  service management legacy tools servicenow worked shift lead managed team support client users across globe created high level service documents facilitated change management process process communication champion delivery unit gptw initiatives resources industry circles apr 2014 – may 2015 initiated idea implemented internal social media page industry group successfully implemented multiple campaigns events within industry group additional information applied learning project fetchizi mobile app singapore create business plan including marketing financial models pitch investment create multiple digital campaigns various social media platforms launch app generate affiliate marketing leads create sales guidelines merchant onboarding applied research project mrs fields cookies  cookieman sydney field study mrs fieldss cookie – perception analysis consumer behavior research 2015 understand customer perceptions cookies made dough sourced locally australia well dough imported us compare analyze whether difference two result changes consumer demand awards  recognitions awarded “second place – entrepreneur sydney” sp jain school global management 2015 awarded “second place – case analysis competition dubai” sp jain school global management 2015 awarded “accenture celebrates excellence awards – gold standard – team category” accenture 2014 awarded “the avanade orange award delivery excellence team” avanade 2014 awarded “the avanade orange award best gptw team” avanade 2014 awarded “the outperformer – merlion” accenture 2012 awarded “all india winner vodafone race fame” mtv 2012 awarded “amaron national karting champion team category  college ” amaron  meco motorsports 2012 ambassador nmims university member department advisory board board studies 2011 professional qualifications skills mcts microsoft sharepoint 2010 application development mcts certified apr 2012 itil v3 foundation itil certified nov 2011 servicenow admin itsm vb macros microsoft office advanced proficiency using applications interest founder member placom cell student placement coordinator batch 2010  2011 brought 4 companies individually placements achieved 100 placements batch size 300 students founder member college fest sattva supervisor sattva 2009 2010 2011 founder soleorganizer sonic boom 10 20 inter college karting event gold medalist running basketball volley ball mba olympics 2016 sport competition held ntu participants mba candidate nus smu sp jain essec business schools mailto imransidihotmailcom https wwwlinkedincominimransidi9898a718',\n",
       "  'hr']]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(prd,contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personal information nationality indian email ...</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        File Content Label\n",
       "0  personal information nationality indian email ...    hr"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(result(prd,contents),columns=['File Content','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ramya_nair_hr.docx\n",
      "1 RajaVenkat[2_3].docx\n",
      "2 ANAZ_A_N.pdf\n",
      "3 Rasal_hr.pdf\n",
      "4 Manjumol_Saleesh_Bengaluru_mrkt.docx\n",
      "5 PRAKASHB_hr.doc\n",
      "6 Pranav_hr.doc\n",
      "7 Premkum_hr.doc\n",
      "8 RajashriGHegde[1_10].doc\n",
      "9 PremSing_hr.pdf\n",
      "10 Laxmi_Kanth_Hyderabad__mrkt.docx\n"
     ]
    }
   ],
   "source": [
    "def test_load():\n",
    "    i=0\n",
    "    test=[]\n",
    "    for file in os.listdir(\"/home/shabna/Desktop/example_codes/new_sample/level3/testmix/\"):\n",
    "        print (i, file)\n",
    "        parsedPDF = parser.from_file(\"/home/shabna/Desktop/example_codes/new_sample/level3/testmix/\"+file)\n",
    "        content = clean_doc(parsedPDF['content'])\n",
    "        test.append(content)\n",
    "        #mat=prpInput(contents)\n",
    "        #prd = model.predict(mat)\n",
    "        #print(result(prd,contents))\n",
    "        #pd.DataFrame(result(prd,contents),columns=['File Content','Label'])\n",
    "        i=i+1\n",
    "        \n",
    "    return test\n",
    "testinput = test_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h=prpInput(testinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1121, 1122, 1123, ...,    0,    0,    0],\n",
       "       [ 762,  540, 1226, ...,    0,    0,    0],\n",
       "       [1354,  567, 1355, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [2089, 2090,  832, ...,    0,    0,    0],\n",
       "       [   4,  274,  711, ...,   94,    3, 2373],\n",
       "       [2374, 2375,  671, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prdi = model.predict(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'hr', 1: 'marketing', 2: 'other', 3: 'seo'}\n"
     ]
    }
   ],
   "source": [
    "rev_lable_index = {}\n",
    "for key in labels_index:\n",
    "    rev_lable_index[labels_index[key]] = key\n",
    "print(rev_lable_index)\n",
    "def result(prdi,testinput):\n",
    "    y_classes = prdi.argmax(axis=-1)\n",
    "    print(\"num of target items:\",len(y_classes))\n",
    "    lx=[]\n",
    "    for idx,lb in enumerate(y_classes):\n",
    "        lx.append([testinput[idx],rev_lable_index[lb]])\n",
    "    return lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of target items: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['yashmin bhatta ramya nair krishna jyothi house near iravichira shiva temple iringole perumbavoor ernakulam contact 9446936288 email ramyavnair231gmailcom mba hr experience nearly 2 years hr operations recruitment  event management profile abridgement enhance knowledge tally 90 mis possessing knowledge interviewing assessing people expert recruiting people according company policy proficient giving valuable decision taking feedback employees core competencies endtoend recruitment  event management employee engagement freelance recruitments work lead team organisational experience 1 la associates perumbavoor la associates established 2013 provides total recruitment solution industrys man power requirements ranges client services include executive search  selection recruitment process outsourcing impeccable speed change technology keeping pace time indomitable challenge la associates helps making staffing requirements perceivable technical filed highly qualified experienced team consultants consultants selfmotivated dynamic well qualified professionals applicants thoroughly screened tested references check match cliental requirements date – jan 2016 till present post  hr executive recruitment sourcing screening resumes various job portals effective strategies screening recruitment lining candidates interview per schedule given client provide complete coordination regarding employment services different client based area 2 gils pvt ltd pune portfolio includes technical nontechnical outsourcing placements training development gardening housekeeping deep cleaning transportation company successfully met complex ever changing business needs leading indian global corporate houses date – feb 2013 dec 2014 post  hr executive recruitment  selection implemented team based work system bring change work design towards achieving selfempowered teams step towards proactive industrial relation policy induction orientation interviewing  selection candidates recruitment  selection joining formalities newly joined employees responsible preparing job description consultation hod’s basis manpower requisition conducting preliminary rounds interviews  written tests arranging  conducting walk – interviews sourcing candidates various portals  employee referral processing requisition offer letter project details project title study training program company piaggio vehicles pvt ltd baramati tenure 60 days description project studied whole process training development help performance management sheets employees provided extensive knowledge training development process company interacting executives attending seminars organisation help project organisation concentrated training employees resulted positive attitudes towards profit orientation automatically improved job knowledge skills levels organisation project training development helped employees organisation foster authenticity openness trust among themselves academic credentials mba human resource vidya pratishthan’s institute information technology baramati pune maharashtra 2012 58 bcom tuljaram chaturchand college baramati pune maharashtra 2010 55 12th commercemaharashtra board vidya pratishthan’s arts science  commerce college baramati maharashtra 2007 53 10th sscmaharashtra board vidya pratishthan’s bal vikas mandir school baramati maharashtra 2005 53 training attended expand market size gain larger sizea marketing strategy perspective india state level seminar “new tax code nature need” focus direct indirect taxes extra curricular activities achievements event organizer vidya pratishthan’s institute information technology baramati pune personal details date birth 23rd january 1990 languages known english hindi marathi malayalam',\n",
       "  'marketing'],\n",
       " ['raja v no11 saraswathy colony email rajavenkat205gmailcom pallavaram chennai mobile 9626634042 zip code – 600 043 career summary highly motivated accomplished professional 6 month experience possesses solid exposure basic analysis idea seo sem smo smm related disciplines background solidly rooted field digital marketing keeps uptodate emerging trends new tools changing best practices search engine optimization blogging content marketing social media platforms ability build  lead highly efficient teams train ethical personnel convey complex concepts understandable terms career progression designation seo analyst clorida infotech technologies ltd since september 2016 upto till date designation backend process executive cameo corporate services ltd since 26022014 25052016 2 year 3 months chennai india technical competencies search engine optimization inbound marketing social media strategy  implementation copywriting personal brand management team training mentoring corporate blog management channel management marketing analysis search engine marketing website analysis design recommendations google analytics  webmaster tool generating leads sales driving traffics channels keyword research analysis competitor’s analysis content management system wordpress web 20 blog postings page page seo strategies local business optimization prepare power point presentations approaches niche guest blogging build quality backlinks familiar seo tools resolve crawl site errors xml sitemap robotstxt creation improve quality score online reputation management accountabilities clorida infotech technologies ltd manage page page optimization page seo activities like providing good content good keywords selection putting keywords correct places giving appropriate title every page xml sitemap creation google map creation good understanding link strategy page seo activities increasing link popularity articles submission forum discussion blog posting qa blog commenting relevant topics classified ads posting directory submission social bookmarking etc following white hat seo technique create quality back links niche based sites high pr sites org edu gov sites monitor serp reports google webmaster tools google analytics daily find resolve crawl errors  site errors help google web master tool analyze new seo strategies participating top seo forums execute new seo link building strategies share gathered knowledge team members assign day day tasks team according seo strategies working knowledge major seo tools create social media business pages twitter facebook google plus linkedin social media sites make periodical updates promoting business pages joining interacting related groupscommunities updated google search algorithms like panda penguin humming bird pirate pigeon note everyday activities excel sheet report clients weekly technical proficiency operating systems windows xp200020032007 2008 scripting languages html css xml programming language basics java c cpp  digital marketing tools google analytics google web master tool google tag manager google adwords adsense seo moz semrush ahrefs woorank majestic seo piwik more strengths ability grasp learn new technology quickly  accurately believe concept “learning job” learning process ongoing one enthusiastic highly motivated positive attitude high levels integrity diligent hardworking personality ability think creatively identify resolve problems conscientious dedication towards progress organization flexibility  adaptability academic profile 2013 be cse annai teresa college engineering anna university secured aggregate 609 cgpa 2009 xii govt hrsec school sirugramam state board secured aggregate 58 2007 x govt hr sec school sirugramam state board secured aggregate 75 personal dossier father’s name tvenkatesan date birth 20th may 1992 gender male nationality indian languages tamil english speak read write hobbies playing cricket listening music mobile 9626634042 declaration hereby declare information facts given true best knowledge belief date your’s sincerely place chennai raja v',\n",
       "  'marketing'],\n",
       " ['indeed resume anaz n kollam kerala anaskrkngmailcom  919562 977 517 seeking position mechanical engineer lecturer  human resource manager education allow make immediate contribution integral part progressive institution willing relocate thiruvananthapuram kerala  kollam kerala work experience well verse engineering drawing principles efficiency work methodically precisely good problem solving skills teaching skill academic projects seminars study gasifier stoves project design fabrication forced draft gasifier stove paper solar energy storage using pcm listening music education mtech mechanical engineering specialisation energy management cusat  kochi kerala 2014 2016 mba human resource management meenakshi university chennai india 2013 2015 btech mechanical engineering university kerala 2009 2013 skills administration driving management research development research teaching technical support technical support engineer additional information strengths 〓 excellent communication skill 〓 ability grasp new skills 〓 hard working 〓 excellent knowledge core mechanical subjects 〓 experienced coordinator social worker 〓 presentation skill',\n",
       "  'hr'],\n",
       " ['microsoft word  rasal hameed cv newdoc page 1 3 curriculum vitae rasal hameed ↸ parekudiyil house pattimattom po cochin  683562 f rasalhryahoocom rasalhrgmailcom f 91 9995881890 04842688189 career objective associated growth oriented organization gives professional satisfaction taking active part growth using knowledge far acquired work turn inspiration actions proficiency forte hr professional offering rich expertise introducing streamlining  administering hr policies procedures  systems recruitment  talent acquisition performance appraisal management payroll  benefits management training  development grievance management employee relations  welfare hr initiatives statutory compliance hr mis reporting exit management expertise introducing implementing clear people strategy ensuring best hr services delivered effectively core hr components capable working fastpaced hightech multicultural environment possessing sound working knowledge entire spectrum hr functions selfmotivated highly passionate  energetic team player great respect people process innovation known clear thinking  flawless execution academic credentials master business administration mba hr pondicherry university master human resource management mhrm pondicherry university bachelor commerce b com mahatma gandhi university pre degree commerce mahatma gandhi university ssc maharashtra state board secondary  higher secondary education diploma computer application  management dcam  page 2 3 quality attributes professional experience nagarjuna herbal concentrates ltd muvattupuzha ernakulam dy manager  hr since 1st feb 2014 till date heading hr dept leading team 2 members serve around 400 employees registered office manufacturing units  area business offices across india managing entire spectrum hr  administrative functions effective functioning hr department reporting executive director lulu international exchange llc cochin  uae hr manager 1st feb 2011 14th nov 2013 heading hr dept leading team 6 members serve around 450 employees across different branches  head office managing entire hr functions ensure delivery professional hr services reporting general manager  chief executive officer jai bharath school management studies perumbavoor asst professor hr 9th nov 2009 31st jan 2011 faculty  resource person mba  mhrm course hr subjects reporting director effective coordination postgraduate hr management course mahatma gandhi university nitta gelatin india limited cochin administrative officer 1st feb 2007 7th nov 2009 managing entire gamut personnel  administration pa functions leading team 2 members serve around 380 employees registered office  manufacturing divisions kerala reporting executive director hr  veega holidays  parks ltd presently wonderla cochin officer  hr 17th jan 2000 31st jan 2007 heading  managing entire spectrum hr functions leading team 3 members serve around 350 employees different departments across organization reporting manager administration  positive attitude  aptitude planning  organizing ability confident  adaptive willingness learn  train good interpersonal skills leadership  team facilitator honesty disciplined  committed sincere loyal  dedicated page 3 3 computer proficiency conversant ms office  word excel powerpoint outlook etc hr software  hr management systems hrms oracle  sql server based  wellversed usage internet intranet  email personal dossier sex male date birth 21st september 1975 marital status married languages known english hindi malayalam  tamil passport details no p5415424 expiry date 03012027 nationality indian driving license valid indian driving license  uae driving license linkedin profile http inlinkedincompubrasalhameed30a7a6b7 references available upon request extracurricular activities life member  national institute personnel management nipm kerala chapter ‘best article awards’ creative writings ‘v  we’ vguard group monthly inhouse magazine  runnerup team member ‘young managers contest 2008’ conducted national institute personnel management nipm kerala chapter organized  coordinated many arts sports cultural  stage programmes consolation prize ‘young managers contest 2008’ conducted kerala management association kma  attended many training programmes seminars  workshop conducted national institute personnel management nipm kerala management association kma  kerala state productivity council kspc  declaration hereby declare information furnished true correct best knowledge belief date 17062017 rasal hameed',\n",
       "  'hr'],\n",
       " ['manjumol 876 2nd floor 7th cross manorayanaplaya sulthanpalya rt nagar bangalore – 560032 email manjumolninangmailcom mobile 9902832406 objective work organization put educational qualifications personal  interpersonal skill maximum  thereby contribute significantly growth enterprise academic qualification course institution year bbm kuvempu univesity shimoga college ss correspondence college bangalore 2013 puc pcmb govt pu college girls malleshwaram 2004 sslc st charles english high school 2002 professional experience executive assistant 6 months kpo erp lead generation 6 years 9 months personnel assistant hr 8 months computer knowledge diploma office management computer basics ms dos windows 982007 xp windows 8 ms office look end user sage crm end user sap crm core competencies ms office ms outlook data management hr  administrations lead generation team handling sales  marketing sw  hw products business development  proposal development project leadership client interaction dealing negotiating customers excellent interpersonal communication skills oral written strong work ethic ability work well within team environment highly motivated team spirit disciplined organized capable taking new responsibilities career history 1 worked executive assistant contract sap labs india pvt ltd aug 2012 jan 2013 2 worked asst manager kpo infodirect data solutions july 2009 july 2012 3 worked manager operations sap east iqmen data labs nov 2005 march 2008 iqmen merged genisys 2008 worked asst manager kpo sap east  byd genisys information systems pvt ltd april 2008 june 2009 4 worked personnel asst hr  personnel department ms indus textile pvt ltd makali bangalore june 2004 jan 2005 appreciation  certificates actively participated school college sports cultural events received certificate essay  debate received certificate appreciation cash reward achieving target attendee success sap business one launch jan 2006  received appreciation management  client target achievement  quality leads erp delivered audience acquisition event attendees rewarded appreciation  cash reward bd activities done infodirect data solutions received certificate appreciation cash reward sap teched techniversity work experience details 1 company name indus textile pvt ltd unit iv makali bangalore designation personnel assistant – personnel department hr duration june 2004 jan 2005 8months role hr executive responsibilities employees  staffs attendance time updation leave management preparing monthly salary reports  sending head office salary disbursal responsible joining formalities new joinees briefing form fill ups  issuing id cards etc esi pf form filling sending head office distribution esi card petty cash voucher maintenance training attended ∙ attendance updation software ∙ fire safety programme ∙ first aid programme 2 company name genisys information systems pvt ltd designation assistant manager kpo sap east  byd  duration nov 2005 june 2009 3 yrs 8 months nov 2005 march 2008 iqmen data labs pvt ltd bangalore iqmen data labs got merged genisys information systems april 2008 april 2008 june 2009 genisys information systems pvt ltd role joined iqmen data labs telecaller nov 2005 lead generator various clients erp team leader campaign management executive audience acquisition – telephonic event registration clients pan india international sap sw leadgen events cry america ibm hw  sw lead gen events mercury events netapps events ibm – srilanka events pcs sw leadgen cookieman seasonal gifting responsibilities managing sap east region a1 b1  byd business analyst team team leader handled team 8 business analyst provide training erp solution inputs objection handling provide case studies briefing industry specific interact data base team lead gen data prepare preplan chart brief analyst inform senior it responsible target achievement set leads target analyst provide data base targeted segment lead gen monitoring team workings  guide set process place reconfirm leads generated update relevant form sent sap lqm client  prepare submit business analyst performance report management daily weekly meetings team management performance appraisal send report higher authority next level attended sap crm training leads generated need sap crm submit respective regional lqm track status n reports user name password given interaction client get trained new products features daily sent leads client tally count attend weekly concall client achieve target submit reports leads update qualified leads count performance quarterly yearly discuss market trends effective improving way qualitative leads queries handling attend meetings sap marketing office bangalore tasks along team handling profiling  lead generation – collecting data telecalling primary  secondary research send mail decision maker companies call position given product create interest convince generate lead fix demo update lead sheet sent marketing  sales person lead generation sap india  ibm server sw group pcs worked shivam mittal’s project – sap erp pharma cro companies cry america calling funds american cry donors headed part event calling team sending reports client attendee list daily wise audience acquisition  events worked sap b1 launch – cxo event business intelligence india group sap users biig year 2006 2007 membership  event yearly 34 events would conducted sap ace awards year 2007  2008 nomination form call event sap customer info day mumbai mercury event load runner net apps event ibm events year 2007 2008 2009 india sri lanka participated team activity  cultural events held iqmen genisys 3 company name infodirect data solutions bangalore designation assistant manager kpo duration july 2009 july 2012 3yrs role executive assistant hr team leader business development data entry lead generation executive assistant – director assist director day day routine works follow up manage fix coordinate meetings create manage calendars schedules contacts documentation mou  agreement signed respective projects responsible proposal development quotation billing invoices producing documents briefing papers reports presentations conduct internet research draft correspondence independently including thank notes emails letters forms hr  administration employee interview joining formalities training attendance salary calculation office administration projects  client handled company data entry kpo company logo website content hosting online free site documents ppt formats contents us resume builder text ms word springer india pvt ltd – data extraction indian institutes database reliance prepaid form fillups ramco ondemand erp ramco systems netsuite proquest solutions erp lead generation partners microsoft oracle tally sap responsibilities  kpo presales activities assisting sales proposals telephonic demonstration company’s services prospective customers discussing concerning ways packages used meet requirements develop execute sales strategy result new business prospecting sales calls presentations proposals closing deals  responsible target achievement client acquisition bringing new projects  business sales  marketing erp lead generation handling projects data entry  kpo beginning end billing  database management create email literatures kpo projects team handling reconfirming leads qc queries objection handling handling queries clients wise work wise maintenance central document database client work  attendance conferences exhibitions preparing presentations client meeting mailer sent company user group meetings 4 company name sap labs indiaa pvt ltd whitefield bengaluru payroll talentpro india pvt ltd designation executive assistant duration aug 2012 jan 2013 6months contract role executive assistant head csr corporate social responsibility global communications sap labs india point contact month service csr project execution reporting nov 2012 deputed marcom marketing communications department csr  marcom activities reporting vp marcom executive assistant head csr apj – csr assist reporting head day day routine works follow up manage fix coordinate meetings create manage calendars schedules contacts coordinate senior members organization access shopping cart plan coordinate travel requirements documentation mou signed respective ngo producing documents briefing papers reports presentations conduct internet research draft correspondence independently including thank notes emails letters forms attend meetings take notes dictation meetings provide general assistance presentations coordination companys csr volunteer department’s staffs deliver projects effectively splitting component activities making sure component assigned prioritized monitored reporting vp marcom marketing communications assists vp marketing communication csr activities ensures consistency within communication materials internal external communication  online offline according corporate design transfers brand positioning respective derivations terms marketing communication activities operative doings support marketing activities new business approachessegments marketing activities product launches printing materials sales support according brand guide braille cards coordinate vendor braille visiting cards employees process billings ngo details updation maintenance ngo vendors details project renewal csr volunteer updation form  dl list – responsible monthly updation new csr volunteer project 1 sap month service 2012 – october it’s sap’s annual csr initiative “sap month service 2012” held across entire month october activities include imparting computer knowledge organizing blood donation camps working ngo centers conducting motivational sessions juvenile homes painting walls government school day month projects pre planned employees volunteer workday also weekends sap’s month service unites sap employees regardless line business cost center geographic locale employees sign month service sap’s inhouse developed charity transformation online platform ‘charitra’ responsibilities reporting new project updated charitra maintain central excel data mos project activity details updating complete list volunteer ambassadors name inumber locations details volunteer ambassador involved respective project contact details send mos registration report volunteer ambassador daily monitoring counts registration volunteer maintain report stock keeping well selected giveaways issue giveaway volunteers participation visiting mos activities place updating monitoring maintenance post project activities writeups photos etc project 2 csr audio recording sap fkom responsible procuring audio recording csr volunteers fkom showcases employees’ dedication emotional engagement month service project 3 sap techniversity  sap teched 2012 team member sap techniversity  sap teched 2012 events company name sap labs india pvt ltd whitefield bengaluru payroll deputed hope foundation designation consultant duration 25 june 2015 24 june 2016 contract role assist head csr corporate social responsibility global communications sap labs india employee engagements csr activities operations management sap csr activities india scope services 1 monitoring programs funded sap 1 operations management sap csr activities 1 organize employee engagement volunteering opportunities sap csr across india including sap month service mos amongst others coordination sap employees sap entities across sap office locations 1 coordination liaison sap ngo partners matter related sap csr 1 support communication pertaining csr report documentation pertaining csr initiatives 1 support sap csr team comprehensively work accordance per guidance sap csr team 1 consultant report head sap csr india personal details name manjumol saleesh husband’s name saleesh samuel date birth 29aug1986 religion christian nationality indian marital status married linguistic capabilities read write english kannada hindi speak english hindi kannada malayalam hobbies surfing net playing violin present address declaration hereby declare information given document accurate  correct best knowledge date place bangalore manjumol saleesh',\n",
       "  'marketing'],\n",
       " ['prakash b address sreenandanam nelliyode tc 641752 1 thiruvallam po thiruvananthapuram kerala 91 8746044337 email id prakashshiva001gmailcom career objective human resources management professional seeks opportunities exposure staffing internal program development management employee relations project management enhance company’s overall strategic plan direction personal strength communication skills confident  positive attitude academia master business administration finance  hr dhanalakshmi srinivasan engineering college anna university – trichy  82 – 2009  2011 bsc mar ivanios college nalanchira – kerala university – 73  2009 computer knowledge ms office internet applications core activities end end recruitment hr generalist areas handling end end recruitment handling joining formalities employees till exit interview ites  non recruitment pms system employee cold calling head hunting conducting induction new employees training candidates interview mis sourcing job portal handling employee grievance  erm shortlisting profiles given requirement – technical non technical assessment processing employee pf esi mediclaim  employment registration forms end end indian payroll management system taking care complete staff data base payroll processing regard labor laws monitoring pf esi pt calculations remittances fillings etc taking care routine tax planning coordination employees monitoring relieving procedures settlements  general administrationrelated work employee coordination  marinating contract employees details employment history currently working speridian technologies pvt ltd us recruiter since oct 2016 till date 1  company name speridian technologies pvt ltd location trivandrum designation recruitment executive oct 2016 till date job profile experience performing needs analysis requirements definition consulting sourcing strategies recruiting screening scheduling interviews reference checking negotiating making offers creating contracts closing candidates help actualize corporate missions etc full execution recruitment process including job posting phone interviewing job interviewing regular communication candidates managers including recruitment administration responsible understand analyze requirements different domain categories administers job interviewing schedules job vacancies keeps promises done job applicants execution recruitment social media communication ruled approved marketing hr marketing principles extensive experience internet recruiting candidates industry leads prescreening quality potential candidates expertise using job portals like dice monster naukri smart recruiters etc handled technologies involving combination complex skill sets rare technologies preparation yearly recruitment plan budget establishes recruiting requirements studying organization plans objectives meeting managers discuss needs conducting recruitment interviews providing necessary inputs hiring process working recruitment agencies source candidates specific job positions possess knowledge sales recruiting processes including sourcing interviewing reference checking tracking salary negotiations closing conducting recruitment interviews providing necessary inputs hiring process keeping track responses  short listing profiles coordinating scheduling  conducting interviews working recruitment agencies source candidates specific job positions effectively recruited candidates internet research internal database referrals strategies maintaining hr records related compensation health medical insurance communicating explaining organizations hr policies employees follow confirmation records statutory obligations  pf esic taxes gratuity lta bonus etc communicating explaining organizations hr policies employees preparation salary statement preparing submitting relevant hr lettersdocumentscertificates per requirement employees consultation management preparing processing timely distribution salary bonus increment salary slip leave encashment full final settlements handling full final settlement employees 2  company name ideoder technologies pvt limited location trivandrum designation sr human resource executive feb 2016 sep 2016 job profile understanding manpower requisition concerned department understanding requirements accordingly drafting job description getting approved concern person sourcing candidates match desired skills screening candidates conducting telephonic interview encouraging employees provide reference better prospects arranging technical interview coordinating concerned person communicating employment status applied candidates maintaining updating database candidates background verification shortlisted candidates particular candidate finalized selected giving offer letter issuing appointment letter brief working agreement policies properly filing relevant document joining required introducing himher team supervisor manager coordinating team get email id made keeping track attendance employees filling leave form keeping track leaves taken handling statutory compliance leave act applicable you minimum salary pf esi medical deductions applicable compliance conducting exit interview candidates resigning issuing relieving letter letter experience full final settlement person 3  company name sobha ltd location bangalore designation sr human resource executive november 2012 january 2016 job profile handling queries employees’ viz salary leaves attendance transfer etc handling employee database soft form files management  leaves attendance management bank account opening id card coordination sending details support staff clarify employee grievance various issuesqueries leave policy salary payment coordinate finance monthly payroll system make joining documents recruiters convey policies rules employees maintain records employees track daily attendance employees present employees performance report front hr manager coordinating various departments requirement 4  company name lotus manpower consultants services pvt ltd location bangalore designation junior hr executive november 2011 november 2012 job profile end end recruitment sourcing staffing scoping boarding candidates screening short listing candidates sourced portal naukri monster times jobs linkedin validating experience interest role lateral hiring identifying right candidates required skill set experience make sure match requirement per jobdescription staffing preparing requisition gathering template sending corresponding sourcing lead initiate sourcing short listing profiles sourced andsending respective hiring managers hiring inputs meeting hiring managers understand niche skill profiles hr round conducting hr round selected candidates negotiating salaries company standards promptly informing rejected candidates reason rejections mis preparing reports closure internal movements offer decline numbers ensure flow work reach aspire rates sending weekly monthly quarterly headcount hiring report vendor management coordinated various manpower consultants procure resources operations across india general screening candidate’s profile shortlisting interviews worked portals background verification background verification carried employees per policy education experience personal details father’s name r babu date birth 18031989 passport p5376912 nationality indian marital status married languages know english malayalam hindi tamil declaration hereby declare – furnished details true proven records place thiruvananthapuram date 05062017 signature prakash b',\n",
       "  'marketing'],\n",
       " ['plot pranav kumar achar contact 91994900196491 9100660266 email id pranavachargmailcom  objective seek highly challenging position area hr bring best also provide excellent learning ground prefect opportunities personal well professional growth summary versatile dynamic hr person 10 years expertise facets hr operations across different industries wants play key role management contribute organization’s effectiveness utilizing managerial skills knowledge diverse hr experience acquired educational profile pg mba sikkim manipal university 2005 specializations human resources  marketing degree bcom vivek vardhani degree college osmania university secunderabad 2002 intermediate commerce kv picket secunderabad cbse  1998 matriculation kv bolarum secunderabad cbse  1996 areas expertise recruitment  workforce planning talent pool selection confirmations  assessments payroll management statutory compliances performance management employee welfare employment summary since jun 2011 – present confidential – retail hyderabad telangana manpower size 700  pan india  dubai manager – hr role hr generalist reporting managing director feb 2010 – may 2011 r brothers retail india pvt ltd – retail hyderabad telangana manpower size 1500 asst manager  hr role hr generalist reporting manager – hr it aug 2006 – dec 2009 mahavir brothers group welkin – fmcg hyderabad manpower size 500 sr executive – hr role hr generalist reporting agm – hr oct 2005 – jul 2006 concept hospitality services pvt ltd – service hyderabad telangana manpower size 100 executive – hr role hr generalist reporting manager – accounts professional skills  key deliverables manpower sourcing  recruitment managing entire life cycle recruitment selection process job portal naukri  times jobs references walk  campus recruitment consultancy identified implemented cost effective source recruitment planning human resource requirements consultation heads different functional  operational areas conducting selection interviews according organization  department charts analyzing actual requirement obtaining approval manpower levels stream lined manpower stores “no excess less manpower” per budget recruitment selection best possible candidates fill vacancies new positions facilitates employee referrals referralbackground checks prepare employment contracts designed new induction presentation familiarize new employee organizational objectives policies compensation benefits administration periodical review pay structures updating salaries  wage structures organization preparing salary packages negotiation taking consideration ctc salary band fixation different levels staff per policy payroll administration ensuring hris  biometric device errorfree processing salary payments employees applicable ensuring accuracy level timeliness payroll inputs master data updation viz newjoiners transfers resigned absconding leave  lops attendance particulars salary accounts reimbursements salary advances  soft loans allowances deductions stop payments payslip disbursement full  final settlements etc employee benefits handling endtoend process group medical insurance policies personal accident policy looking schemes viz uniforms festival gifts best employee awards  etc statutory compliance taking care esi pf bonus gratuity payments per policy training development planning scheduling conducting training programs consultation various departmental heads also coordinating selection skilled trainers employee relation  welfare ensuring prompt resolution employee grievances maintain cordial managementemployee relations take feedback employees check satisfaction level towards organization formal  informal meetings get together open house activities etc attending interpersonal issues arising work place  initiating motivational activities administer associate welfare schemes social security schemes like group insurance medical insurance gratuity per company policy taking care gratuity payment resigned employee handover account dept process taking care staff bonus incentives performance appraisal managing administration performance management program covering levels section employees including periodical performance reviews appraisals linked salary increments promotions coordinated annual pms active members appraisal discussion issuing increment  promotion letters exit formalities counseling employees controlling attrition evaluate escalate reasons leaving taking exit interview taking care full  final settlement process checking final clearance resigned employees accounts dept dues ensuring relieving experience letters issued resigned employees  1 ',\n",
       "  'hr'],\n",
       " ['academic qualifications profile enthusiastic resourceful trainable graduate academic background human resource computer science possess good practical knowledge hr functions objective secure promising position human resource department progressive organization well experienced 1 recruitment selection maintain uptodate recruitment progress report talent database staffing related communication process local recruitment requests effective efficient manner final selection process preparing issuing offer letters clarification offer terms required determining salary selected candidate includes taking necessary approvals sign managing director managing orientation program employee business culture 2 training development interface group hr external vendors suppliers implementation corporate training training programs meet business needs appropriate identify key skills specialty skills propose training needs accordingly managing communicating delivering important projects impact parts organization 3 compensation benefits monitor alert head human resource authorities variance budgeted actual salaries headcount charge payroll administration make necessary coordination make smooth efficient operation variable compensation overtime expatriates compensation special payments  gather necessary data benchmark salaries benefits compile data needed annual salary review annual performance appraisal analysis provide recommendations support hr representatives mainly finance heads  provide information expatriate staffs regarding compensation  benefits tax social benefits  4 employee relations detect handle complaints disputes grievances staffs report head human resources foster conducive working environment employee relations activities communication conduct exit grievance interviews departmentsstaffs assist handling local labor tribunal cases 5 rules regulations review staffs rules regulations employee handbook regular basis create implement employee staff rules regulations newly created subsidiaries organization 6 budget financial management submit personnel budget personnel costs headcount finance department produce submit yearly tax returns staffs yearly basis produce submit payroll journal headcount report finance department monthly basis submit personnel latest estimates personnel costs headcount finance department quarterly basis 7 human resource information system maintain smooth running human resources information system monitor timely update personnel records personal details position salary appraisal outcomes leave records training awards  academic qualifications year course institutionuniversity 20062009 mba – hr bharathiar university coimbatore 20012004 b sc computer science tsa arts  science college perur bharathiar university computer skills operating system windows 98 windows xp languages cobol c c java mark languages html asp jscript packages ms – office work experience duration yrs exp organizations designation hr expereince – 6 years  7 months dec’14 till date 27 orthoone orthopaedic specialty centre pvt ltd coimbatore assistant manager – hr mar’12 nov’14 27 lgb tata motors ltd coimbatore hr officer july ‘09 –mar’12 27 psg hospital institute medical science research coimbatore hr executive marketing expereince – 4 years oct’07  july ‘08 08 tvsundaram iyengar  sons ltd  value trucks division coimbatore chennai business development executive oct ’05 – oct’07 2 tvsundaram iyengar  sons ltd  value trucks division coimbatore customer relation management executive june ’04  oct’05 14 lgb tata motors ltd coimbatore sales cum customer care executive personal qualities positive thinker problem solver multi tasker knowledge hr activities time management skills able juggle multiple priorities meet tight deadlines without compromising quality personal skills strategic planning quick learner creative good verbal written communication proficient making powerpoint presentations good solid team player smartworker languages known english tamil malayalam personal information father’s name k surendiran dob 270584 marital status married nationality indian declaration hereby declare details furnished true best knowledge place coimbatore date prem kumar contact details no17 rajammal illam ezhil nagar ondipudur coimbatore – 641016 phone 99949 69403 email id spr1212gmailcom prem kumar',\n",
       "  'hr'],\n",
       " ['ref srew0406 curriculum vitae rajashri g hegde vinayaka nagar hal bangalore mail rajashrihegde1gmailcom mob 9738798414 career objective seeking opportunity work challenging environment learn new skills enhance company’s growth development explore skills  abilities willing work key player challenging  creative environment always ready learn new things strengths adaptability commitment ability work individually well team good presentation organizing skills good communication  presentation skills grasp new concepts quickly adopt different working environment seo skill site analysisaudit complete technical report website report includes onpage offpage factors website site optimization audits keyword research expert using google ad words keyword tool word tracker tool seo quake even check competitors keywords onpage optimization creating titles keywords descriptions header tags alt tags per major search engine guide lines html validation per w3org standards including dynamic page optimization content analysis reviewing content special focus checking keyword density keyword prominence proximity internal linking expert linking within website effectively per search engine guidelines web site traffic analysis analyze website traffic keywords data includes bounce rate top landing pages exit pages etc using google analytics blog familiar bloggercom wordpress blog integration customization article press releases submitting articles press releases respective directories smo participating submitting links forums social communities bookmarking blogs blog commenting  work experience 1 half  year working experience seo analyst adjetter media network pvt ltd site analysis  page  page optimization keyword research content analysis internal linking website traffic analysis smo handled projects adjetter media network pvt ltd seo team wwwmanipalhospitalscom wwweclinic247com wwwmanipalankurcom noisy radicals educational qualification education level name institution university school year completion percentage mca bsc puc secondary examination rajarajeshwari engineering college blore kittel science college dharwad vijaya pu college mangalore sri siddivinayaka school udupi vtu belgaum karnataka university dharwad karnataka preuniversity board icse new delhi 2013 2010 2007 2005 6900 6412 5100 4700 academic projects mca mini project title leave management system language net sql 2005 mca main project school managementerp company name – bidata trak solutions pvt ltd duration  6 months software used – java jsp apache tomcat 60 database – mysql50 main objective project computerize manual system reduce time consumption staff administrator personal profile name rajashri ganapati hegde father’s name ganapati hegde date birth 15041989 sex female nationality indian marital status married languages known kannada english hobbies chess carom badminton declaration declare information given correct best knowledge  belief place faithfully date rajashri g hegde',\n",
       "  'marketing'],\n",
       " ['resume prem singh email vickslivegmailcom contact 919180935088 synopsis astute hr professional 5 years experience corporate business hr across automotive manufacturing sectors work experience present organization toyota kirloskar motor pvt ltd designation senior officer group leader tenure since october 2015 profile hr management pan india dealerships profile synopsis group lead dealer hr management profile involves strategic control human resource management tracking employee pulse driving hr initiatives toyota dealership spread across india job responsibilities include problem statement identification high employee turnover 51 amongst dealership sales employees resulting inconsistent customer experience low employee morale impact business profits owing lost sales high hiring cost countermeasures initiated 1 conduct employee satisfaction survey understand level employee satisfaction identify grey areas employee retention 2 secondary information source formalize exit interview process understand reasons talent drain based analysis initiated following projects synopsis mentioned foster talent pool mailto vickslivegmailcom 1 compensation  benefits guidelines development standardized guidelines pan india dealership compensation market study development roll  defining salary bands fixed compensation component across band define incentive pay practices line market monitoring implementation challenges across dealerships understanding bottlenecks process developing deploying countermeasures 2 development recruitment guidelines standards lead project development recruitment guidelines dealerships activity involved study dealership culture vis vis understanding competency framework existing employees developing competency frame work target positions development online recruitment tool psychometric tool benchmark job applicant terms behavior fitment defining minimum standards qualification experience age bands etc target positions conducting interviewing skills workshops hr managers dealerships 3 employee satisfaction surveys hr analytics identify areas improvement dealer employee engagement retention employee satisfaction survey support dealer hr managers control manpower turnover study human resource management practices across dealerships identify broadcast best practices amongst dealerships study attrition trend across dealerships conduct root cause analysis develop smart hr metrics incorporated dealer expectation standards balanced scorecard approach measuring individual dealer’s performance 4 development performance management system pms dealer operations scope encompasses defining pms method process formalize pms process creating standardized organization chart developing competency skill framework position dealerships identifying performance parameters every position design tool map performance potential enable hr managers understand career growth roadmap every employee define standards fast track regular track growth paths employees 5 individual development programs assessment every employee dealerships understand behavior patterns share report respective dealer operation create tni matrix functional verticals collaborate development centers develop training modules 6 dealer hr manual development developed manual ready reckoner dealer hr professionals comprehensively including hygiene factors mandatory regulations rewards recognition learning development areas define quantifiable attributes territory managers enable monitor implementation manual additional initiatives 1 star performers award standardized policy recognizing star performers across dealerships recognition performance certificate monetary benefit 2 dealer employee plant visit initiated activity dealer employee’s plant visit intangible recognition performance business impact 1 reduction employee turnover 14 2 average efficiency 42 vehicles per employee 48 vehicles per employee targeted 55 vehicles per employee past experience organization honda 2 wheelers india limited designation executive hr 3rd factory tenure november 2012 september 2015 profile responsibilities 1 organizational development hr analytics benchmarking compensation reward strategies related  competitor businesses conducting market study analyze changing trends compensation rewards design compensation architecture based industry practices assessing data collected hris creating mis reports management benchmarking best practices competitors surrounding industries developing communication matrix help employees common understanding organizational policies understanding policies related concerns though ess one one interactions identifying quantifiable kpi’s individual processes monitoring line ghqs 2 talent acquisition responsible providing end end lateral recruitment solutions filling multiple vacant positions across levels liasioning different business verticals understand requirement accordingly screen desired profiles order provide business competent manpower defined time lines compensation benefit negotiation selected candidates optimizing recruitment cost maximized usage house resources 3 training development lead trainer new recruit induction process orientation coordinating external agencies customize training programs line organization’s modus operandi conceptualizing designing behavior training modules based ojt assessment liasioning different business verticals prospect trainees assessment training effectiveness delivery one one interactions  questionnaires  feedback superiors 4 performance management coordinating hod’s half yearly  annual kra implementation pms line corporate directives hr coordinator annual pms normalizing ratings conducting one one discussion vertical heads normalize ratings annual promotions congruence normal distribution bell curve approach ensuring one one discussions vertical heads associates conducted every cycle 5 quality management tuv certified iso 9001 internal auditor process documentation compliance lead coordinator process quality compliance hr vertical create manage sop’s every hr process line global honda quality standards conduct periodic internal audits verify process compliance line standards previous experience 1 organization tata steel limited designation hr associate corporate hr tenure january 2012 – october 2012 job profile responsibility 1 grievance management system resolving employee concerns  queries personal level coordination respective process owners direct interactions skip level meetings  recording employee feedback suggestions accordingly taking discussion appropriate forum study feasibility implementation identifying key areas concern thorough query analysis ensuring process compliance tqm creating mis ageing analysis 2 joining induction handling pre post joining formalities employee onboarding handling presentation new recruits point contact employee issues queries immediately joining transfer ensuring time delivery entitlements new recruits performing background checks document validation analysis feedback new joinees improving process 3 policy  process implementation direct point contact employees various policies driving hr policy  process implementation awareness designed revamped questionnaires various hr policies regularly tracked employee pulse strategize interventions based need hour educational qualification i masters business administration mba specialization hr marketing icfai university icfai business school ranchi completed end april 2011 secured aggregate 775  ii bca bachelor computer applications birla institute technology mesra ranchi completed year 2009 secured aggregate 769 iii 102 higher school certificate  intermediate science stream cicse board new delhi bishop westcott boys school ranchi completed year 2006 secured aggregate 62 iv 10th secondary school certificate  matriculate cicse board new delhi bishop’s school ranchi completed year 2004 secured aggregate 70 summer internship programme organization aditya birla group–hindalco foils division silvassa tenure 3 months april 24th 2010 till july 24th 2010 internship profile focusing performance management system gaining insights learning impacts organizational performance conducting survey capturing employee voices connection effectiveness pms process industrial visits \\uf0e8 hindustan unilever limited silvassa division \\uf0e8 dabur silvassa branch \\uf0e8 powerica industries \\uf0e8 alok industries \\uf0e8 hindalco industries limited – silvassa foil division \\uf0e8 hindalco industries limited  taloja technical proficiency \\uf0e8 ease windows 7 vista xp earlier generations \\uf0e8 ease ms office 2010 open office \\uf0e8 conversant working linux environment \\uf0e8 niit certified basic level web designer interests \\uf0e8 automobile enthusiast photography personal details date birth 08 – dec – 1988 permanent address prem singh co joginder singh 2001 icon heights beside ice factory campus pragati path old hb road ranchi – 834001 jharkhand  correspondence address prem singh tower e 18 flat no 501 army welfare housing society awho kannamangala whitefield bangalore – 560067',\n",
       "  'marketing'],\n",
       " ['laxmi kanth phone 91 9966222301 email lkrreddyoutlookcom linkedin profile https wwwlinkedincominlaxmikanth2121 professional summary possess 9 years software services product sales experience organized disciplined team player ability excel independent positions requiring minimal supervision ability simultaneously handle multiple tasks skills areas managing inside sales team planning execution lead generation activities prospect contact list building cold calling campaigns email campaigns webinar management crm management thorough knowledge software services technologies key challenges market trends business processes lead generation tools techniques demonstrated expertise preparing corporate templates brochures case studies customer presentations newsletters etc good understanding social media campaigns branding inbound lead generation expertise planning designing corporate websites landing pages well versed intra department coordination achieve marketing sales goals ability design implement corporate reporting skills inside sales lead generation cold calling campaigns email campaigns prospect list preparation crm management webinar management social media campaigns brand management team management reporting market research marketing collaterals preparation experience april 2015 – october 2017 associate director – sales  marketing stravis solutions sales sap servicessolutions targeting prospective customers north american market help inside sales team lead generation help cold calling email campaigns networking webinars prospect contact database building using paid nonpaid sources database lead generation campaign activities recording reporting zoho crm sugar crm preparation cold calling scripts coordinating concalls prospects preparing prospect company profiles handling webinar marketing campaigns continuous interaction technical group management team planning execution social media campaigns responsible organization wide branding responsible preparation marketing collaterals november 2014 – march 2017 manager – business development sunera technologies sales sap servicessolutions targeting prospective customers north american market help inside sales team lead generation help cold calling email campaigns networking webinars prospect contact database building using paid nonpaid sources database lead generation campaign activities recording reporting zoho crm preparation cold calling scripts coordinating concalls prospects preparing prospect company profiles handling webinar marketing campaigns continuous interaction technical group management team responsible preparation marketing collaterals january 2010 – november 2014 manager – business development enterprise one consulting services sales sap servicessolutions targeting prospective customers north american market help inside sales team lead generation help cold calling email campaigns networking webinars prospect contact database building using paid nonpaid sources database lead generation campaign activities recording reporting zoho crm preparation cold calling scripts coordinating concalls prospects preparing prospect company profiles handling webinar marketing campaigns continuous interaction technical group management team planning execution social media campaigns responsible organization wide branding responsible preparation marketing collaterals february 2008 – december 2009 executive – business development prolifics formarly semanticspace technologies sales solutionsservices application development application reengineering migration application maintenance support targeting prospective customers north american market lead generation help cold calling email campaigns networking webinars prospect contact database building using paid nonpaid sources database lead generation campaign activities recording reporting ms dynamics crm preparation cold calling scripts coordinating concalls prospects preparing prospect company profiles handling webinar marketing campaigns continuous interaction technical group us sales team education 2008 masters business administration marketing jawaharlal nehru tchnological university jntu hyderabad 2006 bachelor science mathematics physics copmuter science osmania university hyderabad personal details father’s name n nagi reddy date birth may 24 1984 nationality indian passport number j1242075 marital status married languages know telugu hindi english interests cycling  movies address h f8 gtn industries limited medak unit chitkul v patancheru sangareddy ts  502307 2',\n",
       "  'marketing']]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(prdi,testinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of target items: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yashmin bhatta ramya nair krishna jyothi house...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raja v no11 saraswathy colony email rajavenkat...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indeed resume anaz n kollam kerala anaskrkngma...</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft word  rasal hameed cv newdoc page 1 ...</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manjumol 876 2nd floor 7th cross manorayanapla...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prakash b address sreenandanam nelliyode tc 64...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>plot pranav kumar achar contact 91994900196491...</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>academic qualifications profile enthusiastic r...</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ref srew0406 curriculum vitae rajashri g hegde...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resume prem singh email vickslivegmailcom cont...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>laxmi kanth phone 91 9966222301 email lkrreddy...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         File Content      Label\n",
       "0   yashmin bhatta ramya nair krishna jyothi house...  marketing\n",
       "1   raja v no11 saraswathy colony email rajavenkat...  marketing\n",
       "2   indeed resume anaz n kollam kerala anaskrkngma...         hr\n",
       "3   microsoft word  rasal hameed cv newdoc page 1 ...         hr\n",
       "4   manjumol 876 2nd floor 7th cross manorayanapla...  marketing\n",
       "5   prakash b address sreenandanam nelliyode tc 64...  marketing\n",
       "6   plot pranav kumar achar contact 91994900196491...         hr\n",
       "7   academic qualifications profile enthusiastic r...         hr\n",
       "8   ref srew0406 curriculum vitae rajashri g hegde...  marketing\n",
       "9   resume prem singh email vickslivegmailcom cont...  marketing\n",
       "10  laxmi kanth phone 91 9966222301 email lkrreddy...  marketing"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result(prdi,testinput),columns=['File Content','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
